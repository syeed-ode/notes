	                                                                   |
*************************************************************
*************************************************************
*							    *
*							    *
*							    *
pg 120 - 145
*************************************************************
******       Elasticsearch The Definitive Guide        ******
*************************************************************
Datadog and Klout

No individual part of Elasticsearch is new or revolutionary. Full-text search has been done before, as have analytics systems and distributed databases. The revolution is the combination of these individually useful parts into a single, coherent, real-time application. 

Unfortunately, most databases are astonishingly inept at extracting actionable knowledge from your data. Sure, they can filter by timestamp or exact values, but can they perform full-text search, handle synonyms, and score documents by relevance? Can they generate analytics and aggregations from the same data? Most important, can they do this in real time without big batch-processing jobs?

This is what sets Elasticsearch apart: Elasticsearch encourages you to explore and utilize your data, rather than letting it rot in a warehouse because it is too difficult to query.

Elasticsearch is your new best friend.

CHAPTER 1: You Know, for Search…
Lucene is arguably the most advanced, high-performance, and fully featured search engine library in existence today—both open source and proprietary.

Elasticsearch is also written in Java and uses Lucene internally for all of its indexing and searching, but it aims to make full-text search easy by hiding the complexities of Lucene behind a simple, coherent, RESTful API.


However, Elasticsearch is much more than just Lucene and much more than “just” full-text search. It can also be described as follows:
	• A distributed real-time document store where every field is indexed and searchable
	• A distributed search engine with real-time analytics
	• Capable of scaling to hundreds of servers and petabytes of structured and unstructured data

Installing Marvel
	It looks like Marvel is incompatable with ES 6.2.4, only with 5.0. I need to do more research on this...

	But this error is interesting: 'ERROR: `elasticsearch` directory is missing in the plugin zip'
			[20180411-13:36:21 syeedode:~/elasticsearch-6.2.3] $ bin/elasticsearch-plugin install file:///Users/syeedode/elasticsearch-6.2.3/license-2.4.6.zip 
			-> Downloading file:///Users/syeedode/elasticsearch-6.2.3/license-2.4.6.zip
			[=================================================] 100%   
			ERROR: `elasticsearch` directory is missing in the plugin zip

			https://stackoverflow.com/questions/45987194/elasticsearch-install-custom-plugins-results-in-error-elasticsearch-directory
	
	You must unzip the content of a the zip directory into an elasticsearch directory and then rezip them.
			[20180411-13:40:57 syeedode:~/Downloads] $ mkdir elasticsearch
			[20180411-13:41:08 syeedode:~/Downloads] $ cp license-2.4.6.zip elasticsearch/
			[20180411-13:41:14 syeedode:~/Downloads] $ cd elasticsearch/
			[20180411-13:41:18 syeedode:~/Downloads/elasticsearch] $ unzip license-2.4.6.zip 
				Archive:  license-2.4.6.zip
				  inflating: LICENSE.txt             
				  inflating: plugin-descriptor.properties  
				  inflating: NOTICE.txt              
				  inflating: license-core-2.4.6.jar  
				  inflating: license-plugin-api-2.4.6.jar  
				  inflating: license-2.4.6.jar       
			[20180411-13:41:20 syeedode:~/Downloads/elasticsearch] $ cd ..
			[20180411-13:42:28 syeedode:~/Downloads] $ zip -r elasticsearch-license-2.4.6.zip elasticsearch
				  adding: elasticsearch/ (stored 0%)
				  adding: elasticsearch/license-plugin-api-2.4.6.jar (deflated 29%)
				  adding: elasticsearch/NOTICE.txt (deflated 16%)
				  adding: elasticsearch/license-2.4.6.jar (deflated 14%)
				  adding: elasticsearch/license-core-2.4.6.jar (deflated 11%)
				  adding: elasticsearch/LICENSE.txt (deflated 72%)
				  adding: elasticsearch/plugin-descriptor.properties (deflated 61%)
			[20180411-13:43:15 syeedode:~/elasticsearch-6.2.3] $ bin/elasticsearch-plugin install file:///Users/syeedode/Downloads/elasticsearch-license-2.4.6.zip 
				-> Downloading file:///Users/syeedode/Downloads/elasticsearch-license-2.4.6.zip
				[=================================================] 100%   
				Exception in thread "main" java.lang.IllegalArgumentException: plugin [license] is incompatible with version [6.2.3]; was designed for version [2.4.6]
					at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:237)
					at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:184)
					at org.elasticsearch.plugins.InstallPluginCommand.loadPluginInfo(InstallPluginCommand.java:571)
					at org.elasticsearch.plugins.InstallPluginCommand.installPlugin(InstallPluginCommand.java:707)
					at org.elasticsearch.plugins.InstallPluginCommand.install(InstallPluginCommand.java:623)
					at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:223)
					at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:212)
					at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86)
					at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)
					at org.elasticsearch.cli.MultiCommand.execute(MultiCommand.java:75)
					at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)
					at org.elasticsearch.cli.Command.main(Command.java:90)
					at org.elasticsearch.plugins.PluginCli.main(PluginCli.java:48)

	Ok. Enough of that, let's worry about this later.

	Besides, I'm starting to think that whatever Marvel has to offer, it has subsequently been replaced by kibana.

Running Elasticsearch
	Elasticsearch is now ready to run. You can start it up in the foreground with this:
			./bin/elasticsearch
			/Users/syeedode/elasticsearch-6.2.3/bin/elasticsearch
			/Users/syeedode/elasticsearch-2.4.6/bin/elasticsearch
	
	Add -d if you want to run it in the background as a daemon.
			[20180411-13:47:17 syeedode:~/elasticsearch-6.2.3] $ curl --user elastic:password 'http://localhost:9200/?pretty'
				{
				  "name" : "zxSbBx1",
				  "cluster_name" : "elasticsearch",
				  "cluster_uuid" : "qrSdWDz3QrqAShneKkVnlw",
				  "version" : {
				    "number" : "6.2.3",
				    "build_hash" : "c59ff00",
				    "build_date" : "2018-03-13T10:06:29.741383Z",
				    "build_snapshot" : false,
				    "lucene_version" : "7.2.1",
				    "minimum_wire_compatibility_version" : "5.6.0",
				    "minimum_index_compatibility_version" : "5.0.0"
				  },
				  "tagline" : "You Know, for Search"
				}

	This means that your Elasticsearch cluster is up and running, and we can start experimenting with it. 

	A 'node' is a running instance of Elasticsearch. A 'cluster' is a group of nodes with the same 'cluster.name' that are working together to share data and to provide failover and scale, although a single node can form a cluster all by itself.

	You can shutdown.
			[20180411-14:31:19 syeedode:~/elasticsearch-6.2.3] $ curl --user elastic:password -XPUT http://localhost:9200/shutdown | json_pp
			{
			   "shards_acknowledged" : true,
			   "index" : "shutdown",
			   "acknowledged" : true
			}

Talking to Elasticsearch
	Java API
		Node client - The node client joins a local cluster as a 'non data node'. In other words, it doesn’t hold any data itself, but it knows what data lives on which node in the cluster, and can forward requests directly to the correct node.

		Transport client - The lighter-weight transport client can be used to send requests to a remote cluster. It doesn’t join the cluster itself, but simply forwards requests to a node in the cluster.

		Both Java clients talk to the cluster over port 9300, using the native Elasticsearch transport protocol. The nodes in the cluster also communicate with each other over port 9300. If this port is not open, your nodes will not be able to form a cluster.
				The Java client must be from the same version of Elasticsearch as the nodes; otherwise, they may not be able to understand each other

	RESTful API with JSON over HTTP
		All other languages can communicate with Elasticsearch over port 9200 using a RESTful API, accessible with your favorite web client.
				Elasticsearch provides official clients for several languages -— Groovy, JavaScript, .NET, PHP, Perl, Python, and Ruby -— and there are numerous community-provided clients and integrations, all of which can be found in the Guide.

				https://www.elastic.co/guide/en/elasticsearch/client/index.html

Document Oriented
	Elasticsearch is document oriented, meaning that it stores entire objects or 'documents'.  It not only stores them, but also 'indexes' **the contents** of each document in order to make them searchable.

	In Elasticsearch, you index, search, sort, and filter documents —- not rows of columnar data.

	This is a fundamentally different way of thinking about data and is one of the reasons Elasticsearch can perform complex full-text search.

JSON
	Elasticsearch uses JavaScript Object Notation, or JSON, as the serialization format for documents. JSON serialization has become the standard format used by the NoSQL movement.

Let’s Build an Employee Directory
	
Indexing Employee Documents
	The first order of business is storing employee data. This will take the form of an employee document’: a single document represents a single employee. 

	The act of storing data in Elasticsearch is called 'indexing', but before we can index a document, we need to decide 'where' to store it.

	In Elasticsearch, a 'document' belongs to a 'type', and those 'types' live inside an 'index'.

	You can draw some (rough) parallels to a traditional relational database:
			Relational DB ⇒ Databases ⇒ Tables ⇒ Rows ⇒ Columns
			Elasticsearch ⇒ Indices ⇒ Types ⇒ Documents ⇒ Fields

	An Elasticsearch cluster can contain multiple 'indices' (databases), which in turn contain multiple 'types' (tables). These 'types' hold multiple 'documents' (rows), and each 'document' has multiple 'fields' (columns).

	Index Versus Index Versus Index
		You may already have noticed that the word 'index' is overloaded with several meanings in the context of Elasticsearch. A little clarification is necessary:
				Index (noun) - As explained previously, an 'index' is like a database in a traditional relational database. It is the place to store related 'documents'. The plural of 'index' is 'indices' or 'indexes'.

				Index (verb) - 'To index a document' is to store a document in an 'index (noun)' so that it can be retrieved and queried. It is much like the INSERT keyword in SQL except that, if the 'document' already exists, the new document would replace the old.

				Inverted index - Relational databases add an index, such as a B-tree index, to specific columns in order to improve the speed of data retrieval. Elasticsearch and Lucene use a structure called an 'inverted index' for exactly the same purpose.
						By default, every field in a document is 'indexed' (has an inverted index) and thus is searchable. A field without an 'inverted index' is not searchable. We discuss 'inverted indexes' in more detail in “Inverted Index” on page 81.

						Page 81 is Chapter 6. Mapping and Analysis: Inverted Index: Elasticsearch uses a structure called an inverted index, which is designed to allow very fast full-text searches.

						 An inverted index consists of a list of all the unique words that appear in any document, and for each word, a list of the documents in which it appears.

	So for our employee directory, we are going to do the following:
			• Index a document per employee, which contains all the details of a single employee.
			• Each document will be of type employee.
			• That type will live in the megacorp index.
			• That index will reside within our Elasticsearch cluster.

	In practice, this is easy (even though it looks like a lot of steps). We can perform all of those actions in a single command:
			[20180411-16:40:01 syeedode:~/elasticsearch-6.2.3] $ curl -i -XPUT -H "content-type: application/json; charset=UTF-8" --user elastic:password 'http://localhost:9200/megacorp/employee/1?pretty' -d '{"first_name":"Amiri","last_name":"Baraka","age":25,"about":"I love to go rock climbing","interests":["sports","music"]}'

	Notice that the path /megacorp/employee/1 contains three pieces of information:
			megacorp
				The index name
			employee
				The type name
			1
				The ID of this particular employee

	The response we get back is: 
			HTTP/1.1 201 Created
			Location: /megacorp/employee/1
			content-type: application/json; charset=UTF-8
			content-length: 226

			{
			  "_index" : "megacorp",
			  "_type" : "employee",
			  "_id" : "1",
			  "_version" : 1,
			  "result" : "created",
			  "_shards" : {
			    "total" : 2,
			    "successful" : 1,
			    "failed" : 0
			  },
			  "_seq_no" : 0,
			  "_primary_term" : 1
			}

	There was no need to perform any administrative tasks first, like creating an index or specifying the type of data that each field contains. We could just index a document directly. 

	Elasticsearch ships with defaults for everything, so all the necessary administration tasks were taken care of in the background, using default values.

Retrieving a Document
	We simply execute an HTTP GET request and specify the 'address' of the document -- the 'index', 'type', and 'ID'. Using those three pieces of information, we can return the original JSON document:
			[20180411-16:56:53 syeedode:~/elasticsearch-6.2.3] $ curl -i -XGET --user elastic:password 'http://localhost:9200/megacorp/employee/1?pretty' 

	And the response contains some metadata about the document, and Amiri Baraka’s original JSON document as the _source field:
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 296

			{
			  "_index" : "megacorp",
			  "_type" : "employee",
			  "_id" : "1",
			  "_version" : 2,
			  "found" : true, // note metadata
			  "_source" : {
			    "first_name" : "Amiri",
			    "last_name" : "Baraka",
			    "age" : 25,
			    "about" : "I love to go rock climbing",
			    "interests" : [
			      "sports",
			      "music"
			    ]
			  }
			}
	In the same way that we changed the HTTP verb from PUT to GET in order to retrieve the document, we could use the DELETE verb to delete the document. 

	The HEAD (note the use of -I) verb to check whether the document exists. To replace an existing document with an updated version, we just PUT it again.
			[20180411-17:30:02 syeedode:~/elasticsearch-6.2.3] $ curl -i -IHEAD --user elastic:password 'http://localhost:9200/megacorp/employee/1?pretty' 

Search Lite
	Let’s try something a little more advanced, like a simple search!
			[20180411-17:37:12 syeedode:~/elasticsearch-6.2.3] $ curl -i -XGET --user elastic:password 'http://localhost:9200/megacorp/employee/_search?pretty'

	We’re still using 'index' megacorp and 'type' employee, but instead of specifying a document ID, we now use the '_search' endpoint.

	The response includes all three of our 'documents' in the 'hits' array. By default, a search will return the top 10 results.
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 1302

			{
			  "took" : 49,
			  "timed_out" : false,
			  "_shards" : {
			    "total" : 5,
			    "successful" : 5,
			    "skipped" : 0,
			    "failed" : 0
			  },
			  "hits" : {
			    "total" : 3,
			    "max_score" : 1.0,
			    "hits" : [
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "2",
			        "_score" : 1.0,
			        "_source" : {
			          "first_name" : "Jasmina",
			          "age" : 22,
			          "about" : "I love to build and protect that which I have built.",
			          "last_name" : "Henna",
			          "interests" : "art"
			        }
			      },
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "1",
			        "_score" : 1.0,
			        "_source" : {
			          "first_name" : "Amiri",
			          "age" : 25,
			          "about" : "I love to go rock climbing",
			          "last_name" : "Baraka",
			          "interests" : [
			            "sports",
			            "music"
			          ]
			        }
			      },
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "3",
			        "_score" : 1.0,
			        "_source" : {
			          "first_name" : "Bilal",
			          "age" : 25,
			          "about" : "I love to read",
			          "last_name" : "Ode",
			          "interests" : [
			            "books",
			            "travel"
			          ]
			        }
			      }
			    ]
			  }
			}

	The response not only tells us which documents matched, but also includes the whole document itself: all the information that we need in order to display the search results to the user.

	Next, let’s try searching for employees who have “Baraka” in their last name. To do this, we’ll use a 'lightweight' search method that is easy to use from the command line.

	This method is often referred to as a 'query-string' search, since we pass the search as a URL 'query-string' parameter:
			[20180411-17:51:56 syeedode:~/elasticsearch-6.2.3] $ curl -i -XGET --user elastic:pass 'http://localhost:9200/megacorp/employee/_search?q=last_name:Baraka&pretty'

	We use the same '_search' endpoint in the path, and we add the query itself in the 'q=' parameter. The results that come back show all Barakas:
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 601

			{
			  "took" : 7,
			  "timed_out" : false,
			  "_shards" : {
			    "total" : 5,
			    "successful" : 5,
			    "skipped" : 0,
			    "failed" : 0
			  },
			  "hits" : {
			    "total" : 1,
			    "max_score" : 0.2876821,
			    "hits" : [
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "1",
			        "_score" : 0.2876821,
			        "_source" : {
			          "first_name" : "Amiri",
			          "age" : 25,
			          "about" : "I love to go rock climbing",
			          "last_name" : "Baraka",
			          "interests" : [
			            "sports",
			            "music"
			          ]
			        }
			      }
			    ]
			  }
			}

Search with Query DSL
	Query-string search is handy for ad hoc searches from the command line, but it has its limitations (see “Search Lite” on page 76 (pdf 108)).
			See 5. Searching—The Basic Tools: Search 'Lite'. There are two forms of the search API: a “lite” query-string version that expects all its parameters to be passed in the query string.

			There is also full request body version that expects a JSON 'request body' and uses a rich search language called the query DSL.

	Elasticsearch provides a rich, flexible, query language called the 'query DSL', which allows us to build much more complicated, robust queries.

	The domain-specific language (DSL) is specified using a JSON request body. We can represent the previous search for all Barakas like so:	
			[20180411-18:02:45 syeedode:~/elasticsearch-6.2.3] $ curl -i -XGET -H "content-type: application/json; charset=UTF-8" --user elastic:pass 'http://localhost:9200/megacorp/employee/_search?pretty' -d '{"query":{"match":{"last_name":"Baraka"}}}'

	This will return the same results as the previous query. A number of things have changed. Most notably, this request body uses a match query (one of several types of queries, which we will learn about later).

More-Complicated Searches
	Our query will change a little to accommodate a filter, which allows us to execute structured searches efficiently:
			{
			    "query": {
			        "filtered": {
			            "filter": {
			                "range": {
			                    "age": {
			                        "gt": 30
			                    }
			                }
			            },
			            "query": {
			                "match": {
			                    "last_name": "baraka"
			                }
			            }
			        }
			    }
			}

	IMPORTANT: The filtered query has been deprecated and removed in ES 5.0. You should now use the bool/must/filter query instead.
			// 1 - This portion of the query is a range filter, which will find all ages older than 30 — gt stands for greater than.

			// 2 - This portion of the query is the same match query that we used before. 

	The working query is now:
			curl -i -XGET -H "content-type: application/json; charset=UTF-8" --user elastic:pass 'http://localhost:9200/megacorp/employee/_search?pretty' -d '{"query":{"bool":{"must":{"term":{"last_name":"baraka"}},"filter":{"range":{"age":{"gt":20}}}}}}'

	The compound query now utilizes a different format:
			{
			    "query": {
			        "bool": {
			            "must": {
			                "term": {
			                    "last_name": "baraka"
			                }
			            },
			            "filter": {
			                "range": {
			                    "age": {
			                        "gt": 20
			                    }
			                }
			            }
			        }
			    }
			}

	The result of such a query is:
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 601

			{
			  "took" : 5,
			  "timed_out" : false,
			  "_shards" : {
			    "total" : 5,
			    "successful" : 5,
			    "skipped" : 0,
			    "failed" : 0
			  },
			  "hits" : {
			    "total" : 1,
			    "max_score" : 0.2876821,
			    "hits" : [
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "1",
			        "_score" : 0.2876821,
			        "_source" : {
			          "first_name" : "Amiri",
			          "age" : 25,
			          "about" : "I love to go rock climbing",
			          "last_name" : "Baraka",
			          "interests" : [
			            "sports",
			            "music"
			          ]
			        }
			      }
			    ]
			  }
			}

Full-Text Search
	The searches so far have been simple: single names, filtered by age. Let’s try a more advanced, full-text search—a task that traditional databases would really struggle with.

	We are going to search for all employees who enjoy rock climbing:
			[20180412-00:02:16 syeedode:~/elasticsearch-6.2.3] $ curl -i -XGET -H "content-type: application/json; charset=UTF-8" --user elastic:cfu0blVplXHcUnOkX74u 'http://localhost:9200/megacorp/employee/_search?pretty' -d '{"query":{"match":{"about":"rock climbing"}}}' 

	You can see that we use the same match query as before to search the about field for “rock climbing.” We get back two matching documents:
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 964

			{
			  "took" : 3,
			  "timed_out" : false,
			  "_shards" : {
			    "total" : 5,
			    "successful" : 5,
			    "skipped" : 0,
			    "failed" : 0
			  },
			  "hits" : {
			    "total" : 2,
			    "max_score" : 0.7879545,
			    "hits" : [
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "4",
			        "_score" : 0.7879545,
			        "_source" : {
			          "first_name" : "Fatima",
			          "last_name" : "Baraka",
			          "age" : 32,
			          "about" : "I like to collect rock albums",
			          "interests" : [
			            "music"
			          ]
			        }
			      },
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "1",
			        "_score" : 0.5753642,
			        "_source" : {
			          "first_name" : "Amiri",
			          "age" : 25,
			          "about" : "I love to go rock climbing",
			          "last_name" : "Baraka",
			          "interests" : [
			            "sports",
			            "music"
			          ]
			        }
			      }
			    ]
			  }
			}

	By default, Elasticsearch sorts matching results by their relevance score, that is, by how well each document matches the query.

	But why did Fatima Baraka come back as a result? The reason her document was returned is because the word “rock” was mentioned in her about field. Because only “rock” was mentioned, and not “climbing,” her _score is lower than Amiri’s.
-->			This is not the case in my results... Is that because I've updated Fatima's record a few times? Or becuase of something else?

	This is a good example of how Elasticsearch can search 'within' full-text fields and return the most relevant results first.

	This concept of 'relevance' is important to Elasticsearch, and is a concept that is completely foreign to traditional relational databases, in which a record either matches or it doesn’t.

Phrase Search
	Sometimes you want to match exact sequences of words or phrases. For instance, we could perform a query that will match only employee records that contain both “rock” and “climbing” and that display the words are next to each other in the phrase “rock climbing.”

	To do this, we use a slight variation of the match query called the 'match_phrase' query:
			curl -i -XGET -H "content-type: application/json; charset=UTF-8" --user elastic:cfu0blVplXHcUnOkX74u 'http://localhost:9200/megacorp/employee/_search?pretty' -d '{"query":{"match_phrase":{"about":"rock climbing"}}}'

	This, to no surprise, returns only Amiri Baraka’s document:
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 602

			{
			  "took" : 50,
			  "timed_out" : false,
			  "_shards" : {
			    "total" : 5,
			    "successful" : 5,
			    "skipped" : 0,
			    "failed" : 0
			  },
			  "hits" : {
			    "total" : 1,
			    "max_score" : 0.5753642,
			    "hits" : [
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "1",
			        "_score" : 0.5753642,
			        "_source" : {
			          "first_name" : "Amiri",
			          "age" : 25,
			          "about" : "I love to go rock climbing",
			          "last_name" : "Baraka",
			          "interests" : [
			            "sports",
			            "music"
			          ]
			        }
			      }
			    ]
			  }
			}

Highlighting Our Searches
	Many applications like to 'highlight' snippets of text from each search result so the user can see 'why' the document matched the query.

	Let’s rerun our previous query, but add a new 'highlight' parameter:
			[20180412-00:24:30 syeedode:~/elasticsearch-6.2.3] $ curl -i -XGET -H "content-type: application/json; charset=UTF-8" --user elastic:cfu0blVplXHcUnOkX74u 'http://localhost:9200/megacorp/employee/_search?pretty' -d '{"query":{"match_phrase":{"about":"rock climbing"}},"highlight":{"fields":{"about":{}}}}' 

	Now we get a new section in the response called 'highlight'. This contains a snippet of text from the about field with the matching words wrapped in <em></em> HTML tags:
			HTTP/1.1 200 OK
			content-type: application/json; charset=UTF-8
			content-length: 731

			{
			  "took" : 321,
			  "timed_out" : false,
			  "_shards" : {
			    "total" : 5,
			    "successful" : 5,
			    "skipped" : 0,
			    "failed" : 0
			  },
			  "hits" : {
			    "total" : 1,
			    "max_score" : 0.5753642,
			    "hits" : [
			      {
			        "_index" : "megacorp",
			        "_type" : "employee",
			        "_id" : "1",
			        "_score" : 0.5753642,
			        "_source" : {
			          "first_name" : "Amiri",
			          "age" : 25,
			          "about" : "I love to go rock climbing",
			          "last_name" : "Baraka",
			          "interests" : [
			            "sports",
			            "music"
			          ]
			        },
			        "highlight" : {
			          "about" : [
			            "I love to go <em>rock</em> <em>climbing</em>"
			          ]
			        }
			      }
			    ]
			  }
			}

Analytics
	Finally, we come to our last business requirement: allow managers to run analytics over the employee directory.

	Elasticsearch has functionality called 'aggregations', which allow you to generate sophisticated analytics over your data. 
			It is similar to GROUP BY in SQL, but much more powerful.

	Most fields are indexed by default, which makes them searchable. Aggregations and accessing field values in scripts, however, requires a different access pattern from search.

	Search needs to answer the question "Which documents contain this term?", while sorting and aggregations need to answer a different question: "What is the value of this field for this document?".

	From what I gather things have changed dramatically between 5.0 and 6.2. I'm now reading about how to aggregate in 6.2: https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-aggregations.html

	Aggregations
		The aggregations framework helps provide aggregated data based on a search query. Aggregations can be composed in order to build complex summaries of the data.

		An aggregation can be seen as a unit-of-work that builds analytic information over a set of documents.
				The context of the execution defines what this document set is.

				For example, a top-level aggregation executes within the context of the executed query/filters of the search request.

		There are many different types of aggregations, each with its own purpose and output. 

		To better understand these types, it is often easier to break them into four main families: bucketing, metric, matrix, pipeline.

				Bucketing
					A family of aggregations that build buckets, where each bucket is associated with a key and a document criterion.

					When the aggregation is executed, all the buckets criteria are evaluated on every document in the context.

					When a criterion matches, the document is considered to "fall in" the relevant bucket.

					By the end of the aggregation process, we’ll end up with a list of buckets.

					Each list has a set of documents that "belong" to it.

				Metric
					Aggregations that keep track and compute metrics over a set of documents.

				Matix
					A family of aggregations that operate on multiple fields. 

					The operation produces a matrix result based on the values extracted from the requested document fields.

					Unlike metric and bucket aggregations, this aggregation family does not yet support scripting.

				Pipeline
					Aggregations that aggregate the output of other aggregations and their associated metrics.

		Since each bucket effectively defines a document set one can potentially associate aggregations on the bucket level.

		This is because each set of documents belongs to a bucket. The aggregations will execute within the context of a particular bucket.

		This is where the real power of aggregations kicks in: ** aggregations can be nested **!

	I've skipped this part. There is a major disconnect between the book I'm reading, the 6.2.4 website, and the responses I'm getting.

Distributed Nature
	Elasticsearch is distributed by nature, and it is designed to hide the complexity that comes with being distributed.

	It happily ran the tutorial on a single node living inside your laptop, but if you were to run the tutorial on a cluster containing 100 nodes, everything would work in exactly the same way.

	ES partitions your documents into different containers or shards, which can be stored on a single node or on multiple nodes.

	Balancing these shards across the nodes in your cluster to spread the indexing and search load.

	Duplicating each shard to provide redundant copies of your data, to prevent data loss in case of hardware failure.

	Routing requests from any node in the cluster to the nodes that hold the data you’re interested in.

	Seamlessly integrating new nodes as your cluster grows or redistributing shards to recover from node loss.

	Supplemental chapters will teach you about how the cluster scales and deals with failover (Chapter 2), handles document storage (Chapter 4), executes distributed search (Chapter 9), and what a shard is and how it works (Chapter 11).

	They will provide insight that will make your knowledge of Elasticsearch more complete.

Next steps
	The best way to learn Elasticsearch is by jumping in: just start indexing and searching! However, the more you know about Elasticsearch, the more productive you can become.

	Each chapter explains the essentials, but also includes expert-level tips. 

	If you’re just getting started, these tips are probably not immediately relevant to you. You can always revisit these chapters later, when you are looking to improve performance by shaving off any wasted milliseconds.

	












		










































