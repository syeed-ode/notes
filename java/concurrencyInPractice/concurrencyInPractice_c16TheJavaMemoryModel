	                                                                   |
	                                                                   |
************************************************************************
** Note that a nonzero-length array is always mutable, so it is wrong **
**    for a class to have a public static final array field, or an    **
**               accessor that returns such a field.                  **
************************************************************************
************************************************************************
*							    *
*							    *
*							    *
toc: 
pg 111 - 
************************************************************************************
*******                  Chapter 16 - The Java Memory Model                  *******
************************************************************************************
Throughout this book, we’ve mostly avoided the low-level details of the Java Memory Model (JMM) and instead focused on higher-level design issues such as safe publication, specification of, and adherence to synchronization policies.

These derive their safety from the JMM, and you may find it easier to use these mechanisms effectively when you understand why they work.

This chapter pulls back the curtain to reveal the low-level requirements and guarantees of the Java Memory Model and the reasoning behind some of the higher-level design rules offered in this book.

16.1 What is a memory model, and why would I want one?
	Suppose one thread assigns a value to aVariable: aVariable = 3;

	A memory model addresses the question “Under what conditions does a thread that reads aVariable see the value 3?” There are a number of reasons a thread might not immediately—or ever—see the results of an operation in another thread. 
			Compilers may generate instructions in a different order than the “obvious”, 

			or store variables in registers instead of in memory; 

			processors may execute instructions in parallel or out of order; 

			caches may vary the order in which writes to variables are committed to main memory; 

			and values stored in processor-local caches may not be visible to other processors.

			These factors can prevent a thread from seeing the most up-to-date value for a variable and can cause memory actions in other threads to appear to happen out of order—if you don’t use adequate synchronization.

	In a single-threaded environment, all these tricks played on our program by the environment are hidden from us and have no effect other than to speed up execution. 

	The Java Language Specification allows for the JVM to have, as long as the program has the same result as if it were executed in program order in a strictly sequential environment, all these games be permissible. 

	These rearrangements are responsible for much of the improvement in computing performance in recent years.

-->	It is only when multiple threads share data that it is necessary to coordinate their activities, and the JVM relies on the program to identify when this is happening by
	using synchronization.

The JMM specifies the minimal guarantees the JVM must make about when writes to variables become visible to other threads.

	16.1.1 Platform memory models
		In a shared-memory multiprocessor architecture, each processor has its own cache that is periodically reconciled with main memory. 

		Processor architectures provide varying degrees of 'cache coherence'; 
				Some provide minimal guarantees that allow different processors to see different values for the same memory location at virtually any time.

		The operating system, compiler, and runtime (and sometimes, the program, too) must make up the difference between what the hardware provides and what thread safety requires.
				Ensuring that every processor knows what every other processor is doing at all times is expensive. 

				Most of the time this information is not needed, so processors relax their memory-coherency guarantees to improve performance.

	An architecture’s memory model tells programs what guarantees they can expect from the memory system, and specifies the special instructions required (called 'memory barriers' or 'fences') to get the additional memory coordination guarantees required when sharing data.
		
		In order to shield the Java developer from the differences between memory models across architectures, Java provides its own memory model, the JMM. 

		The JVM deals with the differences between the JMM and the underlying platform’s memory model by inserting memory barriers at the appropriate places.

		There is a happy, if unrealistic, model called the 'sequential consistency'. It is
				One convenient mental model for program execution is to imagine that there is a single order in which the operations happen in a program, regardless of what processor they execute on, and that each read of a variable will see the last write in the execution order to that variable by any processor.

		Software developers often mistakenly assume sequential consistency, but no modern multiprocessor offers sequential consistency and the JMM does not either.
				The classic sequential computing model, the von Neumann model, is only a vague approximation of how modern multiprocessors behave.

		The bottom line is that modern shared-memory multiprocessors (and compilers) can do some surprising things when data is shared across threads, unless you’ve told them not to through the use of memory barriers.

		Fortunately, Java programs need not specify the placement of memory barriers; they need only identify when shared state is being accessed, through the proper use of synchronization.

	16.1.2 Reordering
		In describing race conditions and atomicity failures in Chapter 2, we used interaction diagrams depicting “unlucky timing” where the scheduler interleaved operations so as to cause incorrect results in insufficiently synchronized programs.
				To make matters worse, the JMM can permit actions to appear to execute in different orders from the perspective of different threads.

				The various reasons why operations might be delayed or appear to execute out of order can all be called 'reordering'.

		PossibleReordering in Listing 16.1 illustrates how difficult it is to reason about the behavior of even the simplest concurrent programs unless they are correctly synchronized. 

		 		// Insufficiently synchronized program that can have surprising results. 'Don’t do this'.
		 		public class PossibleReordering {
					static int x = 0, y = 0;
					static int a = 0, b = 0;
	
					public static void main(String[] args) throws InterruptedException {
						
						Thread one = new Thread(new Runnable() {
							public void run() {
								a = 1;
								x = b;
							}
						});
						
						Thread other = new Thread(new Runnable() {
							public void run() {
								b = 1;
								y = a;
							}
						});
						
						one.start(); other.start();

						one.join(); other.join();

						System.out.println("( "+ x + "," + y + ")");
					}
				}

				// Figure 16.1: Interleaving showing reordering in PossibleReordering.
				ThreadA ---> x=b(0) ------------------> reorder ----> a=1
				ThreadB--------------> b=1 ---> y=a(0)

		It is fairly easy to imagine how PossibleReordering could print (1, 0), or (0, 1), or (1, 1):
				Thread A could run to completion before B starts, B could run to completion before A starts, or their actions could be interleaved.

		But, strangely, PossibleReordering can also print (0, 0)!
				The actions in each thread have no dataflow dependence on each other, and accordingly can be executed out of order.

				Even if they are executed in order, the timing by which caches are flushed to main memory can make it appear, from the perspective of B, that the assignments in A occurred in the opposite order.

				Figure 16.1 shows a possible interleaving with reordering that results in printing (0, 0).

		PossibleReordering is a trivial program, and it is still surprisingly tricky to enumerate its possible results. Reordering at the memory level can make programs behave unexpectedly.

		Synchronization inhibits the compiler, runtime, and hardware from reordering memory operations in ways that would violate the visibility guarantees provided by the JMM.
				On most popular processor architectures, the memory model is strong enough that the performance cost of a volatile read is in line with that of a nonvolatile read.






































































































