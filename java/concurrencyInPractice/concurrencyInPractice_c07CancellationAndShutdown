	                                                                   |
	                                                                   |
************************************************************************
** Note that a nonzero-length array is always mutable, so it is wrong **
**    for a class to have a public static final array field, or an    **
**               accessor that returns such a field.                  **
************************************************************************
************************************************************************
**  Executor is the basis for task execution that 1) supports a wide  **
**     variety of task execution policies, 2) provides a means of     **
**decoupling task submission from task execution, and 3) provides life**
**     cycle support for statistics gathering, app management, and    **
**                             monitoring                             **
************************************************************************
************************************************************************
*							    *
*							    *
*							    *
toc: 
pg 131 - 
************************************************************************************
*******                      Chapter 6 - Task Execution                     ********
************************************************************************************
Most concurrent applications are organized around the execution of 'tasks': abstract, discrete units of work.
		Dividing the work of an application into tasks 
				simplifies program organization, 
				
				facilitates error recovery by providing natural transaction boundaries, 

				and promotes concurrency by providing a natural structure for parallelizing work.
************************************************************************
**Tasks are 'independent' activities: work that doesn’t depend on the **
**    state, result, or side effects of other tasks. Independence     **
**  facilitates concurrency as independent tasks can be executed in   **
**       parallel if there are adequate processing resources.         **
************************************************************************
************************************************************************
**  Executor is the basis for task execution that 1) supports a wide  **
**     variety of task execution policies, 2) provides a means of     **
**decoupling task submission from task execution, and 3) provides life**
**     cycle support for statistics gathering, app management, and    **
**                             monitoring                             **
************************************************************************
6.1 Executing tasks in threads
	The first step in organizing a program around task execution is identifying sensible 'task boundaries'.

	Tasks are 'independent' activities: work that doesn’t depend on the state, result, or side effects of other tasks. 
			Independence facilitates concurrency, as independent tasks can be executed in parallel if there are adequate processing resources. 

			For greater flexibility in scheduling and load balancing tasks, each task should also represent a small fraction of your application’s processing capacity.

	Server applications should exhibit both 'good throughput' and 'good responsiveness' under normal load.

	Further, applications should exhibit 'graceful degradation' as they become overloaded, rather than simply falling over under heavy load.

	Choosing good task boundaries, coupled with a sensible 'task execution policy' (see Section 6.2.2), can help achieve these goals.

6.1.1 Executing tasks sequentially
	There are a number of possible policies for scheduling tasks within an application, some of which exploit the potential for concurrency better than others.

	The simplest is to execute tasks sequentially in a single thread. We’re interested in characterizing the concurrency of various scheduling policies.
			class SingleThreadWebServer {
				public static void main(String[] args) throws IOException {
					ServerSocket socket = new ServerSocket(80);
					while (true) {
						Socket connection = socket.accept();
						handleRequest(connection);
					}
				}
			}
			Listing 6.1. Sequential web server. (One thread for all requests.)

	'SingleThreadedWebServer' would perform poorly in production because it can handle only one request at a time. 
			While the server is handling a request, new connections must wait until it finishes the current request and calls accept again.

			In a single-threaded server, blocking (for socket I/O due to network congestion or connectivity problems, or file I/O or make database requests) not only delays completing the current request, but prevents pending requests from being processed at all. 

			If one request blocks for an unusually long time, users might think the server is unavailable because it appears unresponsive.

6.1.2 Explicitly creating threads for tasks
	A more responsive approach is to create a new thread for servicing each request, as shown in ThreadPerTaskWebServer in Listing 6.2.
			class ThreadPerTaskWebServer {
				public static void main(String[] args) throws IOException {
					ServerSocket socket = new ServerSocket(80);
					while (true) {
						final Socket connection = socket.accept();
						Runnable task = new Runnable() {
							public void run() {
								handleRequest(connection);
							}
						};
						new Thread(task).start();
					}
				}
			}
			Listing 6.2. Web server that starts a new thread for each request.

	ThreadPerTaskWebServer is similar in structure to the single-threaded version—the main thread still alternates between 
			accepting an incoming connection and 

			dispatching the request. 

	The difference is that for each connection, the main loop creates a new thread to process the request instead of processing it within the main thread. This has three main consequences:
			Task processing is offloaded from the main thread, 
					This enables the main loop to resume waiting for the next incoming connection more quickly.

					This enables new connections to be accepted before previous requests complete

					**Improving responsiveness.**

			Tasks can be processed in parallel, enabling multiple requests to be serviced simultaneously. 
					This may improve throughput if there are multiple processors, or if tasks need to block for any reason such as I/O completion, lock acquisition, or resource availability.

			Task-handling code must be thread-safe, because it may be invoked concurrently for multiple tasks.

	As long as the request arrival rate does not exceed the server’s capacity to handle requests, this approach offers better responsiveness and throughput.

6.1.3 Disadvantages of unbounded thread creation
	For production use, the thread-per-task approach has some practical drawbacks, especially when a large number of threads may be created:
			Thread lifecycle overhead:
				Thread creation and teardown are not free. The actual overhead varies across platforms, but thread creation takes time, introducing latency into request processing, and requires some processing activity by the JVM and OS. If requests are frequent and lightweight, creating a new thread for each request can consume significant computing resources.

			Resource consumption
				Active threads consume system resources, especially memory. When there are more runnable threads than available processors, threads sit idle.

				Having many idle threads can tie up a lot of memory, putting pressure on the garbage collector, and having many threads competing for the CPUs can impose other performance costs as well. 

				If you have enough threads to keep all the CPUs busy, creating more threads won’t help and may even hurt.

			Stability
				There is a limit on how many threads can be created, based on the requested stack size in the Thread constructor et al.

				When you hit this limit, the most likely result is an OutOfMemoryError. Trying to recover from such an error is very risky; it is far easier to structure your program to avoid hitting this limit.

	Up to a certain point, more threads can improve throughput, but beyond that point creating more threads just slows down your application, and creating one thread too many can cause your entire application to crash horribly.

	The way to stay out of danger is to place some bound on how many threads your application creates, and to test your application thoroughly to ensure that, even when this bound is reached, it does not run out of resources.

	The problem with the thread-per-task approach is that nothing places any limit on the number of threads created.
			So a malicious user, or enough ordinary users, can make your web server crash if the traffic load ever reaches a certain threshold, this is a serious failing.

************************************************************************
**Tasks are 'independent' activities: work that doesn’t depend on the **
**    state, result, or side effects of other tasks. Independence     **
**  facilitates concurrency as independent tasks can be executed in   **
**       parallel if there are adequate processing resources.         **
************************************************************************
************************************************************************
**  Executor is the basis for task execution that 1) supports a wide  **
**     variety of task execution policies, 2) provides a means of     **
**decoupling task submission from task execution, and 3) provides life**
**     cycle support for statistics gathering, app management, and    **
**                             monitoring                             **
************************************************************************
6.2 The Executor framework
	Tasks are logical units of work, and threads are a mechanism by which tasks can run asynchronously.
			We’ve examined two policies for executing tasks using threads—execute tasks sequentially in a single thread, and execute each task in its own thread.

	Both have serious limitations: the sequential approach suffers from poor responsiveness and throughput, and the thread-per-task approach suffers from poor resource management.

	In Chapter 5, we saw how to use 'bounded queues' to prevent an overloaded application from running out of memory.

	'Thread pools' offer the same benefit for thread management, and 'java.util.concurrent' provides a flexible thread pool implementation as part of the Executor framework.

-->	The primary abstraction for task execution in the Java class libraries is not Thread, but Executor, shown in Listing 6.3.
			public interface Executor {
				void execute(Runnable command);
			}
			Listing 6.3. Executor interface.

	'Executor' may be a simple interface, but it forms the basis for a flexible and powerful framework for asynchronous task execution that supports a wide variety of task execution policies.

	It provides a standard means of decoupling 'task submission' from 'task execution', describing tasks with Runnable.

	The 'Executor' implementations also provide lifecycle support and hooks for adding statistics gathering, application management, and monitoring.

	Executor is based on the producer-consumer pattern, where activities that submit tasks are the producers (producing units of work to be done) and the threads that execute tasks are the consumers (consuming those units of work).

-->	'Using an Executor is usually the easiest path to implementing a producer-consumer design in your application.'

6.2.1 Example: web server using Executor
	'TaskExecutionWebServer' in Listing 6.4 replaces the hard-coded thread creation with an Executor.
			class TaskExecutionWebServer {
				// a fixed-size thread pool with 100 threads
				private static final int NTHREADS = 100;

				// we use one of the standard Executor implementations
				private static final Executor exec = Executors.newFixedThreadPool(NTHREADS);
				
				public static void main(String[] args) throws IOException {
					ServerSocket socket = new ServerSocket(80);
					while (true) {
						final Socket connection = socket.accept();
						Runnable task = new Runnable() {
							public void run() {
								handleRequest(connection);
							}
						};
						exec.execute(task);
					}
				}
			}

	In 'TaskExecutionWebServer', submission of the request-handling task is decoupled from its execution using an Executor. 
			Its behavior can be changed merely by substituting a different Executor implementation.

			Changing Executor implementations or configuration is far less invasive than changing the way tasks are submitted.

			Executor configuration is generally a one-time event and can easily be exposed for deployment-time configuration.
					Task submission code tends to be strewn throughout the program and harder to expose.

	We can easily modify TaskExecutionWebServer to behave like ThreadPerTaskWebServer by substituting an Executor that creates a new thread for each request. 
			Writing such an Executor is trivial, as shown in ThreadPerTaskExecutor in Listing 6.5.
					public class ThreadPerTaskExecutor implements Executor {
						public void execute(Runnable r) {
							new Thread(r).start();
						};
					}
					Listing 6.5. Executor that starts a new thread for each task.

	Similarly, it is also easy to write an Executor that would make TaskExecutionWebServer behave like the single-threaded version. 
			This means executing each task synchronously (not running the next task until the 'run()' method completes) before returning from execute, as shown in WithinThreadExecutor in Listing 6.6.
					public class WithinThreadExecutor implements Executor {
						public void execute(Runnable r) {
							r.run();
						};
					}
					Listing 6.6. Executor that executes tasks synchronously in the calling thread. (This is the single threaded version.)
p. 136
6.2.2 Execution policies
	The value of decoupling submission from execution is that it lets you easily specify, and change, the execution policy for a tasks.

	An execution policy specifies the “what, where, when, and how” of task execution, including:
			In what thread will tasks be executed?

			In what order should tasks be executed (FIFO, LIFO, priority order)?

			How many tasks may execute concurrently?

			How many tasks may be queued pending execution?

			If a task has to be rejected because the system is overloaded, which task should be selected as the victim, and how should the application be notified?

			What actions should be taken before or after executing a task?

	Execution policies are a resource management tool, and the optimal policy depends on the available computing resources and your quality-of-service requirements.
			By limiting the number of concurrent tasks, you can ensure that the application does not fail due to resource exhaustion. 

			It also assures the app won't suffer performance problems due to contention for scarce resources. 
					This is analogous to one of the roles of a transaction monitor in an enterprise application. 

					It can throttle the rate at which transactions are allowed to proceed so as not to exhaust or overstress limited resources.

			Separating the specification of execution policy from task submission makes it practical to select an execution policy at deployment time that is matched to the available hardware.

	Whenever you see code of the form:
			new Thread(runnable).start()
	
	And you think you might at some point want a more flexible execution policy, seriously consider replacing it with the use of an Executor.

6.2.3 Thread pools
	A thread pool, manages a homogeneous pool of worker threads. it is tightly bound to a 'work queue' holding tasks waiting to be executed.

	Worker threads have a simple life: request the next task from the work queue, execute it, and go back to waiting for another task.

	Executing tasks in a pool of threads has a number of advantages over the threadper-task approach.
			Reusing an existing thread instead of creating a new one amortizes thread creation and teardown costs.

			Since the worker thread often already exists at the time the request arrives, the latency associated with thread creation does not delay task execution. 
-->					This improves responsiveness.

			By properly tuning the size of the thread pool, you can have enough threads to keep the processors busy while not having so many that your application runs out of memory or thrashes due to competition among threads for resources.

	The class library provides a flexible thread pool implementation along with some useful predefined configurations. You can create a thread pool by calling one of the static factory methods in Executors:
			newFixedThreadPool
				A fixed-size thread pool creates threads as tasks are submitted, up to the maximum pool size, and then attempts to keep the pool size constant (adding new threads if a thread dies due to an unexpected Exception).

			newCachedThreadPool
				A cached thread pool has more flexibility to reap idle threads when the current size of the pool exceeds the demand for processing, and to add new threads when demand increases, but places no bounds on the size of the pool.

			newSingleThreadExecutor
				A single-threaded executor creates a single worker thread to process tasks, replacing it if it dies unexpectedly. Tasks are guaranteed to be processed sequentially according to the order imposed by the task queue (FIFO, LIFO, priority order).
						Single-threaded executors also provide sufficient internal synchronization to guarantee that any memory writes made by tasks are visible to subsequent tasks.

						This means that objects can be safely confined to the “task thread” even though that thread may be replaced with another from time to time.

			newScheduledThreadPool
				A fixed-size thread pool that supports delayed and periodic task execution, similar to Timer. (See Section 6.2.5.)

			The newFixedThreadPool and newCachedThreadPool factories return instances of the general-purpose ThreadPoolExecutor, which can also be used directly to construct more specialized executors. We discuss thread pool configuration options in depth in Chapter 8.

	The web server in TaskExecutionWebServer uses an Executor with a bounded pool of worker threads. 

	Submitting a task with execute adds the task to the work queue.
-->			The worker threads repeatedly dequeue tasks from the work queue and execute them.

	Switching from a thread-per-task policy to a pool-based policy has a big effect on application stability: the web server will no longer fail under heavy load.
			It also degrades more gracefully, since it does not create thousands of threads that compete for limited CPU and memory resources. 

			Using an Executor opens the door to all sorts of additional opportunities for tuning, management, monitoring, logging, error reporting, and other possibilities that would have been far more difficult to add without a task execution framework.
			
			While the server may not fail due to the creation of too many threads, if the task arrival rate exceeds the task service rate for long enough it is still possible (just harder) to run out of memory. 

			This is because of the growing queue of Runnables awaiting execution. This can be addressed within the Executor framework by using a bounded work queue—see Section 8.3.2.

6.2.4 Executor lifecycle
	We’ve seen how to create an Executor but not how to shut one down.

	The JVM can’t exit until all the (nondaemon) threads have terminated, so failing to shut down an Executor could prevent the JVM from exiting.

	Because an Executor processes tasks asynchronously, at any given time the state of previously submitted tasks is not immediately obvious.
			In shutting down an application, there is a spectrum from graceful shutdown (finish what you’ve started but don’t accept any new work) to abrupt shutdown (turn off the power to the machine room), and various points in between.

			Since Executors provide a service to applications, they should be able to be shut down as well, both gracefully and abruptly, and feed back information to the application about the status of tasks that were affected by the shutdown.

	The ExecutorService interface extends Executor, adding a number of methods for lifecycle management. 
			As well as some convenience methods for task submission.

			This interface addresses the issue of execution service lifecycle.
					public interface ExecutorService extends Executor {
						void shutdown();
						List<Runnable> shutdownNow();
						boolean isShutdown();
						boolean isTerminated();
						boolean awaitTermination(long timeout, TimeUnit unit)
						throws InterruptedException;
						// ... additional convenience methods for task submission
					}

	The lifecycle implied by ExecutorService has three states —- running, shutting down, and terminated.
			ExecutorServices are initially created in the running state.

			The shutdown method initiates a graceful shutdown: no new tasks are accepted but previously submitted tasks are allowed to complete—including those that have not yet begun execution.

			The shutdownNow method initiates an abrupt shutdown: it attempts to cancel outstanding tasks and does not start any tasks that are queued but not begun.

	Tasks submitted to an ExecutorService after it has been shut down are handled by the rejected execution handler (see Section 8.3.3), which might silently discard the task or might cause execute to throw the unchecked RejectedExecutionException.

	Once all tasks have completed, the ExecutorService transitions to the terminated state.
			You can wait for an ExecutorService to reach the terminated state with awaitTermination, or poll for whether it has yet terminated with isTerminated. 

			It is common to follow shutdown immediately by awaitTermination, creating the effect of synchronously shutting down the ExecutorService. 

			(Executor shutdown and task cancellation are covered in more detail in Chapter 7.)

	LifecycleWebServer in Listing 6.8 extends our web server with lifecycle support. It can be shut down in two ways: programmatically by calling stop, and through a client request by sending the web server a specially formatted HTTP request.
			class LifecycleWebServer {
				private final ExecutorService exec = ...;
	
				public void start() throws IOException {
					ServerSocket socket = new ServerSocket(80);

					while (!exec.isShutdown()) {
						try {
							final Socket conn = socket.accept();

							exec.execute(new Runnable() {
								public void run() { handleRequest(conn); }
							});
						} catch (RejectedExecutionException e) {
							if (!exec.isShutdown())
								log("task submission rejected", e);
						}
					}
				}

				public void stop() { exec.shutdown(); }

				void handleRequest(Socket connection) {
					Request req = readRequest(connection);
					if (isShutdownRequest(req))
						stop();
					else
						dispatchRequest(req);
				}
			}
			Listing 6.8. Web server with shutdown support.

6.2.5 Delayed and periodic tasks
	The 'Timer' facility manages the execution of deferred (“run this task in 100 ms”) and periodic (“run this task every 10 ms”) tasks.

	'Timer' has some drawbacks, and 'ScheduledThreadPoolExecutor' should be thought of as its replacement.
			'Timer' does have support for scheduling based on absolute, not relative time, so that tasks can be sensitive to changes in the system clock; 'ScheduledThreadPoolExecutor' supports only relative time.

	You can construct a 'ScheduledThreadPoolExecutor' through its constructor or through the 'newScheduledThreadPool' factory.

	If a timer task takes too long to run, the timing accuracy of other TimerTasks can suffer. This is because a 'Timer' creates only a single thread for executing timer tasks.
			If a recurring TimerTask is scheduled to run every 10 ms and another TimerTask takes 40 ms to run
					The recurring task if it was scheduled at fixed rate, gets called four times in rapid succession after the long-running task completes.

					Or if it is a fixed delay, “misses” four invocations completely.

	Scheduled thread pools address this limitation by letting you provide multiple threads for executing deferred and periodic tasks.

	Another problem with Timer is that it behaves poorly if a TimerTask throws an unchecked exception. The Timer thread doesn’t catch the exception, so an unchecked exception thrown from a TimerTask terminates the timer thread.
			Timer also doesn’t resurrect the thread in this situation; instead, it erroneously assumes the entire Timer was cancelled. 

			In this case, TimerTasks that are already scheduled but not yet executed are never run, and new tasks cannot be scheduled. 

	This problem, called “thread leakage” is described in Section 7.3, along with techniques for avoiding it.

	'ScheduledThreadPoolExecutor' deals properly with ill-behaved tasks; there is little reason to use Timer in Java 5.0 or later.

6.3 Finding exploitable parallelism
	The Executor framework makes it easy to specify an execution policy, but in order to use an Executor, you have to be able to describe your task as a Runnable.

	But sometimes good task boundaries are not quite so obvious, as in many desktop applications.

	In this section we develop several degrees of concurrency. Our sample component is the page-rendering portion of a browser application.

6.3.1 Example: sequential page renderer
	The simplest approach is to process the HTML document sequentially. 
			As text markup is encountered, render it into the image buffer; as image references are encountered, 
					fetch the image over the network and draw it into the image buffer as well. 

					This is easy to implement and requires touching each element of the input only once 

					It doesn’t even require buffering the document. 

			This is likely to annoy the user, who may have to wait a long time before all the text is rendered.

	A less annoying but still sequential approach involves rendering the text elements first, 
			We could leave rectangular placeholders for the images, and after completing the initial pass on the document. 

			We could then go back and download the images and draw them into the associated placeholder. 

			This approach is shown in SingleThreadRenderer in Listing 6.10.
					public class SingleThreadRenderer {

					    void renderPage(CharSequence source) {
					        renderText(source);

					        List<ImageData> imageData = new ArrayList<ImageData>();

					        for (ImageInfo imageInfo : scanForImageInfo(source))
					            imageData.add(imageInfo.downloadImage());

					        for (ImageData data : imageData)
					            renderImage(data);
					    }

					    private void renderText(CharSequence source) {

					    }

					    private void renderImage(ImageData data) {

					    }

					    // Downloads the images
					    private List<ImageInfo> scanForImageInfo(CharSequence source) {
					        return Arrays.asList(new ImageInfo[0]);
					    }
					}
			Downloading an image mostly involves waiting for I/O to complete, and during this time the CPU does little work. 

	So the sequential approach may underutilize the CPU, and also makes the user wait longer than necessary to see the finished page.

	We can achieve better utilization and responsiveness by breaking the problem into independent tasks that can execute concurrently.

************************************************************************
**Tasks are 'independent' activities: work that doesn’t depend on the **
**    state, result, or side effects of other tasks. Independence     **
**  facilitates concurrency as independent tasks can be executed in   **
**       parallel if there are adequate processing resources.         **
************************************************************************
************************************************************************
**  Executor is the basis for task execution that 1) supports a wide  **
**     variety of task execution policies, 2) provides a means of     **
**decoupling task submission from task execution, and 3) provides life**
**     cycle support for statistics gathering, app management, and    **
**                             monitoring                             **
************************************************************************
6.3.2 Result-bearing tasks: Callable and Future	
	The Executor framework uses Runnable as its basic task representation. 
-->			Runnable is a fairly limiting abstraction; 'run()' cannot return a value or throw checked exceptions. 

			It can have side effects such as writing to a log file or placing a result in a shared data structure.

	Many tasks are effectively deferred computations -— executing a database query, fetching a resource over the network, or computing a complicated function.

	For these types of tasks, 'Callable' is a better abstraction: it expects that the main entry point, call, will return a value and anticipates that it might throw an exception.
			To express a non-value-returning task with 'Callable', use 'Callable<Void>'.

	 		'Executors' includes several utility methods for wrapping other types of tasks, including 'Runnable' and 'java.security.PrivilegedAction', with a 'Callable'.

	'Runnable' and 'Callable' describe abstract computational tasks. Tasks are usually finite: they have a clear starting point and they eventually terminate.

	The lifecycle of a task executed by an Executor has four phases: created, submitted, started, and completed.
			Since tasks can take a long time to run, we also want to be able to cancel a task. 

			In the Executor framework, tasks that have been submitted but not yet started can always be cancelled. 

			Tasks that have started can sometimes be cancelled if they are responsive to interruption. 

			Cancelling a task that has already completed has no effect.

-->	'Future' represents the lifecycle of a task and provides methods to test the status of a task. 
			It provides whether the task has completed or been cancelled, retrieve its result, and cancel the task.

	Implicit in the specification of 'Future' is that task lifecycle can only move forwards, not backwards —- just like the 'ExecutorService' lifecycle. 
			Once a task is completed, it stays in that state forever.
					public interface Callable<V> {
					    V call() throws Exception;
					}
					public interface Future<V> {
					    boolean cancel(boolean mayInterruptIfRunning);
					    boolean isCancelled();
					    boolean isDone();
					    V get() throws InterruptedException, ExecutionException, CancellationException;
					    V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, CancellationException, TimeoutException;
					}
					// Listing 6.11. Callable and Future interfaces.

	The behavior of get varies depending on the task state (not yet started, running, completed).
			It returns immediately or throws an Exception if the task has already completed.

			If the task is not completed it blocks until the task completes.
					If the task completes by throwing an exception, get rethrows it wrapped in an ExecutionException.

					If get throws ExecutionException, the underlying exception can be retrieved with getCause.

			If the task was cancelled, get throws CancellationException.

	There are several ways to create a Future to describe a task. 
			The submit methods in ExecutorService all return a Future, so that you can submit a Runnable or a Callable to an executor and get back a Future that can be used to retrieve the result or cancel the task. 

			You can also explicitly instantiate a FutureTask for a given Runnable or Callable. 

			Because FutureTask implements Runnable, it can be submitted to an Executor for execution or executed directly by calling its run method.

			ExecutorService implementations can override newTaskFor in AbstractExecutorService to control instantiation of the Future corresponding to a submitted Callable or Runnable. 

			The default implementation just creates a new FutureTask, as shown in Listing 6.12.
					public abstract class AbstractExecutorService implements ExecutorService {
					    /**
					     * Returns a {@code RunnableFuture} for the given callable task.
					     *
					     * @param callable the callable task being wrapped
					     * @param <T> the type of the callable's result
					     * @return a {@code RunnableFuture} which, when run, will call the
					     * underlying callable and which, as a {@code Future}, will yield
					     * the callable's result as its result and provide for
					     * cancellation of the underlying task
					     * @since 1.6
					     */
					    protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) {
					        return new FutureTask<T>(callable);
					    }
					}
					Listing 6.12. Default implementation of newTaskFor in ThreadPoolExecutor.

			Submitting a Runnable or Callable to an Executor constitutes a safe publication (see Section 3.5) of the Runnable or Callable from the submitting thread to the thread that will eventually execute the task. 

			Similarly, setting the result value for a Future constitutes a safe publication of the result from the thread in which it was computed to any thread that retrieves it via get.

6.3.3 Example: page renderer with Future
	As a first step towards making the page renderer more concurrent, let’s divide it into two tasks, one that renders the text and one that downloads all the images. 

	Because one task is largely CPU-bound and the other is largely I/O-bound, this approach may yield improvements even on single-CPU systems.
	                                                                   |
	'Callable' and 'Future' can help us express the interaction between these cooperating tasks.

	In FutureRenderer in Listing 6.13, we create a Callable to download all the images, and submit it to an ExecutorService. 
			This returns a Future describing the task’s execution; 

			When the main task gets to the point where it needs the images, it waits for the result by calling Future.get. 

			If we’re lucky, the results will already be ready by the time we ask; otherwise, at least we got a head start on downloading the images. 
					public class FutureRenderer {

					    private static final int NTHREADS = 100;
					    private final ExecutorService executor = Executors.newFixedThreadPool(NTHREADS);

					    void renderPage(CharSequence source) {
					        final List<ImageInfo> imageInfos = scanForImageInfo(source);
					        
					        Callable<List<ImageData>> task =
					                new Callable<List<ImageData>>() {
					                    public List<ImageData> call() {
					                        List<ImageData> result = new ArrayList<ImageData>();
					                        for (ImageInfo imageInfo : imageInfos)
					                            result.add(imageInfo.downloadImage());
					                        return result;
					                    }
					                };

					        Future<List<ImageData>> future = executor.submit(task);

					        renderText(source);

					        try {
					        	// When all the images are downloaded, they are rendered onto the page
					            List<ImageData> imageData = future.get();

					            for (ImageData data : imageData)
					                renderImage(data);
					        } catch (InterruptedException e) {

					            // Re-assert the thread’s interrupted status
					            Thread.currentThread().interrupt();

					            // We don’t need the result, so cancel the task too
					            future.cancel(true);
					        } catch (ExecutionException e) {
					            throw launderThrowable(e.getCause());
					        }
					    }
					    Listing 6.13. Waiting for image download with Future.

	The state-dependent nature of get means that the caller need not be aware of the state of the task.
			The safe publication properties of task submission and result retrieval make this approach thread-safe. 

			The exception handling code surrounding Future.get deals with two possible problems: that the task encountered an Exception. 

			The thread calling get was interrupted before the results were available. (See Sections 5.5.2 and 5.4.)

	This is an improvement in that the user sees a result quickly and it exploits some parallelism, but we can do considerably better.

	There is no need for users to wait for all the images to be downloaded; they would probably prefer to see individual images drawn as they become available.

6.3.4 Limitations of parallelizing heterogeneous tasks
	In the last example, we tried to execute two different types of tasks in parallel -— downloading the images and rendering the page.

	But obtaining significant performance improvements by trying to parallelize sequential heterogeneous tasks can be tricky.

	Two people can divide the work of cleaning the dinner dishes fairly effectively: one person washes while the other dries. 
			However, assigning a different type of task to each worker does not scale well; 
			
			If several more people show up, it is not obvious how they can help without getting in the way or significantly restructuring the division of labor. 

			Without finding finer-grained parallelism among similar tasks, this approach will yield diminishing returns.

	A further problem with dividing heterogeneous tasks among multiple workers is that the tasks may have disparate sizes. 
			If you divide tasks A and B between two workers but A takes ten times as long as B, you’ve only speeded up the total process by 9%. 

			Finally, dividing a task among multiple workers always involves some amount of coordination overhead; for the division to be worthwhile.

			This overhead must be more than compensated by productivity improvements due to parallelism.

	FutureRenderer uses two tasks: one for rendering text and one for downloading the images. 
			If rendering the text is much faster than downloading the images, the resulting performance is not much different from the sequential version.

			But the code is a lot more complicated.

	Thus, trying to increase concurrency by parallelizing heterogeneous activities can be a lot of work, and there is a limit to how much additional concurrency you can get out of it. 
			See Sections 11.4.2 and 11.4.3 for another example of the same phenomenon.

	The real performance payoff of dividing a program’s workload into tasks comes when there are a large number of independent, 'homogeneous' tasks that can be processed concurrently.

pg 147
6.3.5 CompletionService: Executor meets BlockingQueue
	If you have a batch of computations to submit to an 'Executor' and you want to retrieve their results as they become available. 
			You could retain the 'Future' associated with each task and repeatedly poll for completion by calling get with a timeout of zero.

	This is possible, but tedious. Fortunately there is a better way: a 'completion service'.

	'CompletionService' combines the functionality of an 'Executor' and a 'BlockingQueue'.

	You can submit 'Callable' tasks to it for execution and use the queuelike methods take and poll to retrieve completed results, packaged as 'Future's, as they become available.

	'ExecutorCompletionService' implements 'CompletionService', delegating the computation to an 'Executor'. 

	The implementation of ExecutorCompletionService is quite straightforward.
			The ExecutorCompletionService constructor creates a BlockingQueue to hold the completed results.
					public class ExecutorCompletionService<V> implements CompletionService<V> {
					    private final Executor executor;
					    private final BlockingQueue<Future<V>> completionQueue;

					    public ExecutorCompletionService(Executor executor) {
					        if (executor == null) throw new NullPointerException();

					        this.executor = executor;

					        this.aes = (executor instanceof AbstractExecutorService) ? (AbstractExecutorService) executor : null;
					        
					        this.completionQueue = new LinkedBlockingQueue<Future<V>>();
					    }
					}

			When a task is submitted, it is wrapped with a QueueingFuture, a subclass of FutureTask. 
					public class ExecutorCompletionService<V> implements CompletionService<V> {
					    public Future<V> submit(Callable<V> task) {
					        if (task == null) throw new NullPointerException();
					        RunnableFuture<V> f = newTaskFor(task);  // Returns new FutureTask<V>(task, result);
					        executor.execute(new QueueingFuture(f));
					        return f;
					    }
					}

			FutureTask has a done method that is called when the computation completes. The 'QueueingFuture' overrides 'done()' to place the result on the BlockingQueue, as shown in Listing 6.14.
					public class ExecutorCompletionService<V> implements CompletionService<V> {
					    /**
					     * FutureTask extension to enqueue upon completion
					     */
					    private class QueueingFuture extends FutureTask<Void> {
					        QueueingFuture(Callable<V> c) { super(c); }
					        QueueingFuture(Runnable t, V r) { super(t, r); }
					        QueueingFuture(RunnableFuture<V> task) {
					            super(task, null);
					            this.task = task;
					        }
					        protected void done() { completionQueue.add(task); }
					        private final Future<V> task;
					    }
					}

			The 'take()' and 'poll()' methods delegate to the BlockingQueue, blocking if results are not yet available.
					public class ExecutorCompletionService<V> implements CompletionService<V> {
					   public Future<V> take() throws InterruptedException {
					        return completionQueue.take();
					    }

					    public Future<V> poll() {
					        return completionQueue.poll();
					    }

					    public Future<V> poll(long timeout, TimeUnit unit) throws InterruptedException {
					        return completionQueue.poll(timeout, unit);
					    }
					}

6.3.6 Example: page renderer with CompletionService
	We can use a 'CompletionService' to improve the performance of the page renderer in two ways: 'shorter total runtime' and 'improved responsiveness'.

	Improvement in runtime can occur by doing two things:
			We can create a separate task for downloading each image and execute them in a thread pool, turning the sequential download into a parallel one. 

			This reduces the amount of time to download all the images.

	Improving the responsiveness and give the user a more dynamic interface.
			By fetching results from the CompletionService and rendering each image as soon as it is available.
					public class Renderer {
					    private final ExecutorService executor;

					    Renderer(ExecutorService executor) { this.executor = executor; }

					    void renderPage(CharSequence source) {
					        List<ImageInfo> info = scanForImageInfo(source);
					        CompletionService<ImageData> completionService = new ExecutorCompletionService<ImageData>(executor);

					        for (final ImageInfo imageInfo : info) {
					            // Separate task to download each image <--> improves runtime
					            // was
					            // new Callable<ImageData>() {
					            //  public ImageData call() {
					            //      return imageInfo.downloadImage();
					            //  }
					            // }
					            completionService.submit( () -> imageInfo.downloadImage() );
					        }

					        renderText(source);

					        try {
					            for (int t = 0, n = info.size(); t < n; t++) {
					                // Fetching results from the CompletionService and rendering each image as soon as it is available.
					                Future<ImageData> f = completionService.take();
					                ImageData imageData = f.get();
					                renderImage(imageData);
					            }
					        } catch (InterruptedException e) {
					            Thread.currentThread().interrupt();
					        } catch (ExecutionException e) {
					            throw launderThrowable(e.getCause());
					        }
					    }
					}

	Multiple ExecutorCompletionServices can share a single Executor, so it is perfectly sensible to create an ExecutorCompletionService that is private to a particular computation while sharing a common Executor.
			When used in this way, a 'CompletionService' acts as a handle for a batch of computations. 

			This is just like how a Future acts as a handle for a single computation. 

			By remembering how many tasks were submitted to the CompletionService and counting how many completed results are retrieved. 

			You can know when all the results for a given batch have been retrieved, even if you use a shared Executor.

149
6.3.7 Placing time limits on tasks
	Sometimes, if an activity does not complete within a certain amount of time, the result is no longer needed and the activity can be abandoned.

	The primary challenge in executing tasks within a time budget is making sure that you don’t wait longer than the time budget to get an answer or find out that one is not forthcoming.

	The timed version of Future.get supports this requirement: it returns as soon as the result is ready, but throws TimeoutException if the result is not ready within the timeout period.

	A secondary problem when using timed tasks is to stop them when they run out of time. 
			This way they do not waste computing resources by continuing to compute a result that will not be used. 

			This can be accomplished by having the task strictly manage its own time budget and abort if it runs out of time. 

			You could also execute this by cancelling the task if the timeout expires. 

			Future can help; if a timed get completes with a TimeoutException, you can cancel the task through the Future. 

			If the task is written to be cancellable (see Chapter 7), it can be terminated early so as not to consume excessive resources. 

			This technique is used in Listings 6.13 and 6.16.

	It generates a composite web page that contains the requested content plus an advertisement fetched from an ad server. 
		    /**
		     * renderPageWithAd
		     *
		     * It generates a composite web page that contains the requested content
		     * plus an advertisement fetched from an ad server.
		     *      1) It submits the ad-fetching task to an executor
		     *      2) Computes the rest of the page content, and then waits for the
		     *         ad until its time budget runs out.
		     *              The timeout passed to get is computed by subtracting the
		     *              current time from the deadline; this may in fact yield a
		     *              negative number, but all the timed methods in
		     *              java.util.concurrent treat negative timeouts as zero, so
		     *              no extra code is needed to deal with this case.
		     *      3) If the 'get()' times out, it cancels the ad-fetching task and uses
		     *         a default advertisement instead.
		     *              The 'true' parameter to 'Future.cancel' means that the
		     *              task thread can be interrupted if the task is currently
		     *              running; see Chapter 7
		     *
		     * @param source
		     * @return
		     * @throws InterruptedException
		     */
		    Page renderPageWithAd(CharSequence source) throws InterruptedException {
		        // Create the deadline for
		        long endNanos = System.nanoTime() + TIME_BUDGET;

		        // This is the advertisement fetched from an ad server.
		        // Submitting the ad-fetching task to an executor
		        Future<Ad> f = executor.submit(new FetchAdTask());

		        // Render the page while waiting for the ad
		        // Computing the rest of the page content
		        Page page = renderPageBody();
		        Ad ad;
		        try {
		            // Only wait for the remaining time budget
		            // The timeout passed to 'get' is computed by subtracting the
		            //      current time from the deadline
		            //
		            long timeLeft = endNanos - System.nanoTime();

		            ad = f.get(timeLeft, NANOSECONDS);
		        } catch (ExecutionException e) {
		            ad = DEFAULT_AD;
		        } catch (TimeoutException e) {
		            // If the 'get()' times out, it cancels the ad-fetching task
		            //      and uses a default advertisement instead.
		            ad = DEFAULT_AD;
		            f.cancel(true);
		        }
		        page.setAd(ad);
		        return page;
		    }

6.3.8 Example: a travel reservations portal
	The time-budgeting approach in the previous section can be easily generalized to an arbitrary number of tasks.

	Consider a travel reservation portal: the user enters travel dates and requirements and the portal fetches and displays bids from a number of airlines, hotels or car rental companies.
			Rather than have the response time for the page be driven by the slowest response, present only the information available within a given time budget.

			For providers that do not respond in time, the page could either omit them completely or display a placeholder such as “Did not hear from Air Java in time.”

	It would be easy enough to create n tasks, submit them to a thread pool, retain the Futures, and use a timed get to fetch each result sequentially via its Future, but there is an even easier way —- invokeAll.

	Listing 6.17 uses the timed version of invokeAll to submit multiple tasks to an ExecutorService and retrieve the results.
			public class TravelQuoteService {
			    private static final int NTHREADS = 100;
			    private final ExecutorService exec = Executors.newFixedThreadPool(NTHREADS);

			    public List<TravelQuote> getRankedTravelQuotes(TravelInfo travelInfo
			                                                , Set<TravelCompany> companies
			                                                , Comparator<TravelQuote> ranking
			                                                , long time
			                                                , TimeUnit unit) throws InterruptedException {

			        List<QuoteTask> tasks = new ArrayList<QuoteTask>();

			        companies.stream().map(company -> tasks.add(new QuoteTask(company, travelInfo)));

			        // The invokeAll method takes a collection of tasks
			        // and returns a collection of Futures.
			        //      The two collections have identical structures
			        // The invokeAll method:
			        //      1) adds the Futures to the returned collection in the order imposed by the task collection’s iterator
			        //      2) this allows the caller to associate a 'Future' with the 'Callable' it represents
			        //      3) (timed version) will return when
			        //          a) all the tasks have completed
			        //          b) the calling thread is interrupted
			        //          c) the timeout expires
			        //      4) any tasks that are not complete when the timeout expires are cancelled
			        //
			        // On return from invokeAll, each task will have either completed normally or been cancelled; 
			        // the client code can call get or isCancelled to find
			        List<Future<TravelQuote>> futures = exec.invokeAll(tasks, time, unit);

			        List<TravelQuote> quotes = new ArrayList<TravelQuote>(tasks.size());

			        Iterator<QuoteTask> taskIter = tasks.iterator();

			        for (Future<TravelQuote> f : futures) {
			            QuoteTask task = taskIter.next();
			            try {
			                quotes.add(f.get());
			            } catch (ExecutionException e) {
			                quotes.add(task.getFailureQuote(e.getCause()));
			            } catch (CancellationException e) {
			                quotes.add(task.getTimeoutQuote(e));
			            }
			        }
			        Collections.sort(quotes, ranking);
			        return quotes;
			    }
			}

Summary
	Structuring applications around the execution of tasks can simplify development and facilitate concurrency.

	The 'Executor' framework permits you to decouple task submission from execution policy and supports a rich variety of execution policies.

-->	Whenever you find yourself creating threads to perform tasks, consider using an Executor instead.

	You must identify sensible task boundaries. Some analysis may be required to uncover finer-grained exploitable parallelism.













































