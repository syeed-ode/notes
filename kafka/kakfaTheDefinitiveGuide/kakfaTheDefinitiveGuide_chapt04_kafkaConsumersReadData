Add 23 to the page to get the pdf location. A page references are in PDF pages.
*************************************************************
*							 *
*							 *
*							 *
toc: 20
pg43 - 
*************************************************************
*** Chapter 4 - Kafka Consumers: Reading Data from Kafka ****
*************************************************************	
Kafka Definitive Guide
Kafka Consumer Concepts - 63 (86 of 322) 
	Consumers and Consumer Groups
			Suppose you have an application that needs to 
					read messages from a Kafka topic, 

					run some validations against them, and 

					write the results to another data store. 

			In this case your application will 
					create a consumer object, 

					subscribe to the appropriate topic, and 

					start receiving messages, 

					validating them and 

					writing the results. 

					This may work well for  a  while,  but  what  if  the  rate  at  which  producers  write  messages  to  the  topic exceeds  the  rate  at  which  your  application  can  validate  them?  

					Obviously there  is  a  need  to  scale  consumption  from  topics.

					Just  like  multiple  producers  can write to the same topic, 

			We need to allow multiple consumers to read from the same topic, splitting the data between them.

			Kafka consumers are typically part of a consumer group.
					When multiple consumers are subscribed to a topic and belong to the same consumer group, 

			Each consumer in the group will receive messages from a different subset of the partitions in the topic.
					Let’s take topic T1 with four partitions. Now suppose we created a new consumer, C1,which  is  the  only  consumer  in  group  G1, 
							Consumer C1 will get all messages from all four t1 partitions.

					If we add another consumer, C2, to group G1, each consumer will only get messagesfrom two partitions. 

					If  G1  has  four  consumers,  then  each  will  read  messages  from  a  single  partition.

					If  we  add  more  consumers  to  a  single  group  with  a  single  topic  than  we  have  parti‐tions, some of the consumers will be idle and get no messages at all.

			The main way we scale data consumption from a Kafka topic is by adding more consumers  to  a  consumer  group.
					It  is  common  for  Kafka  consumers  to  do  
							high-latency operations such as write to a database or a 

							time-consuming computation on the data.

			This  is  a good reason to create topics with a large number of partitions:
					our  main  method  of  scaling is

					adding more consumers that share the load by 

					having each consumer own just  a  subset  of  the  partitions  and  messages

					it allows adding moreconsumers  when  the  load  increases.

			Keep  in  mind  that  there  is  no  point  in  adding more consumers than you have partitions in a topic
					some of the consumers will just be idle

					In addition to adding consumers in order to scale a single application, 
			
			It is very common to have multiple applications that need to read data from the same topic.
					One of the main design goals in Kafka was to make the data produced to Kafka topics
							available  for  many  use  cases  throughout  the  organization. In  those  cases,  

							we  want each application to get all of the messages rather than just a subset

			Ensure  the  application  has  its  own  consumer  group, 
					to make sure anapplication  gets  all  the  messages  in  a  topic.

					Kafka  scales  to  a  large number of consumers and consumer groups without reducing performance.

					if we add a new consumer group G2 with a single consumer,
							this consumer will get all the messages in topic T1 independent of what G1 is doing

							G2 can have more than a single consumer, in which case they will each get a subset of partitions,

							but G2 as a whole will still get all the messages regardless of other consumer groups.

			To  summarize,
					you  create  a  new  consumer  group  for  each  application  that  needs  allthe  messages  from  one  or  more  topics

					you  add  consumers  to  an  existing  consumergroup to scale the reading and processing of messages from the topics
							so each addi‐tional consumer in a group will only get a subset of the messages.

	Consumer Groups and Partition Rebalance
			Consumers in a consumer group share ownershipof the partitions in the topics they subscribe to
					When we add a new consumer to the group, it starts consuming messages from partitions previously consumed by another consumer. 

					The same thing happens when a consumer shuts down or crashes; it leaves the  group,  and  

			when a consumer shuts down the  partitions  it  used  to  consume  will  be  consumed  by  one  of  the remaining  consumers

			Reassignment  of  partitions  to  consumers  also  happen  whenthe  topics  the  consumer  group  is  consuming  are  modified
					if  an  administrator adds new partitions

			Rebalancing
					Moving  partition  ownership  from  one  consumer  to  another

					Rebalances allowing us to easily and safely add and remove consumers
							in  the  normal  course  of  events  they  are  fairly  undesirable.  
									During  a  rebalance,  consumers can’t consume messages 

					so a rebalance is basically a short window of unavailability  of  the  entire  consumer  group.
							when  partitions  are  moved  from one  consumer  to  another,  the  consumer  loses  its  current  state;
									if  it  was  caching  any data,  it  will  need  to  refresh  its  caches

									slowing  down  the  application  until  the  consumer  sets  up  its  state  again.

					Throughout  this  chapter  we  will  discuss  how  to  safely handle rebalances and how to avoid unnecessary ones

			Heartbeats (skipping for right now) - pg 67 (90 of 322)

			How Does the Process of Assigning Partitions to Brokers Work?
					When  a  consumer  wants  to  join  a  group,  it  sends  a  JoinGroup request  to  the  group  coordinator.

					The  first  consumer  to  join  the group  becomes  the  group  leader.
							The  leader  receives  a  list  of  all consumers  in  the  group  from  the  group  coordinator  
									(this  willinclude  all  consumers  that  sent  a  heartbeat  recently  and  

									which  are therefore considered alive) and 

							The  leader is responsible for assigning a subset of partitions to each consumer.
									It uses an implementation of PartitionAssignor  to  decide  which  partitions  should  be  handled  by which consumer.


							The  consumer  leader  sends  the  list  of assignments  to  the  GroupCoordinator
									The  GroupCoordinator sends  this  information to all the consumers

									the  leader  is  the  only  client  process  that  has  
											the  full  list  of consumers   in   the   group   and   

											their   assignments

											Each consumer only sees his own assignment

Creating a Kafka Consumer
	(skipping the notes for now...need to expidite the process)


‐
































































