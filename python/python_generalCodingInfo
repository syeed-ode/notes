This information was gathered from reading Effective Python
*
*
*
*
****    Chapter 2 - Functions    ****
Item 14: Prefer Exceptions to Returning None
	Functions that return 'None' to indicate special meaning are error prone 
		because 'None' and other values (e.g., zero, the empty string) all 
		evaluate to 'False' in conditional expressions.
	Raise exceptions to indicate special situations instead of returning 'None'. Expect the calling 
		code to handle exceptions properly when they're documented.

Item 13: Take advantage of Each Block in try/except/else/finally
	There are four distinct times you may want to take action during exception handling in Python: 
		'try', 'except', 'else', and 'finally' blocks.  Each block serves a unique purpose.
	'Finally' Blocks
		Use the 'try/finally' when you want exeptions to propgate up, but you also want to run 
			cleanup code even when exceptions occur. 
			[ handle = open('random_data.txt') try: data = hanlde.read() finally: handle.close() ]. 
			This code assures that if handle.read() throws an exception, handle.close() still 
			runs.
		Note: open() runs prior to the try: block.  If open throws and exception, we do not 
			want handle.close() to run at all.
	'Else' Blocks
		Use 'try/except/else' to make it clear which exceptions will be handled by your code 
			and which exceptions will propagate up.  When the 'try' block doesn't raise an 
			exception, the 'else' block will run. 
		The 'else' block helps you minimize the amount of code in the 'try' block and visually 
			distinguish the success case from the 'try/except' blocks. It improves 
			readability (think, KeyManager code in java).
	Everything Together
		Use 'try/except/else/finally' when you want to do it in one compound statement.  Here, 
		the 'try' block is used to read the file and process it. The 'except' block is used to 
		handle exceptions from the 'try' block that are excpected.  The 'else' block is used to 
		update the file in place and to allow related exceptions to propagate up. The 'finally' 
		block cleans up the file handle.

<Item 39: Use 'Lock' to Prevent Data Races in Threads>
Item 43: Consider 'contextlib' and 'with' Statements for Reusable 'try/finally' 
	Behavior
		The 'with' statement is used to indicate when code is running in a 
			special context.  A good example is mutual exclusion blocks in 
			'with' statements to indicate that the intented code only runs 
			while the lock is held. 
			[ lock = Lock(); with lock: print('Lock is held') ]. This 
			example is equivalent to this 'try/finally' construction 
			because the Lock class properly enables the 'with' statement. 
			[ lock.acquire(); try: print('Lock is held'); finally: lock.release() ]
		The 'with' statement version is better because it eliminates the need to 
			write the repetitive code of the 'try/finally' block. It is easy
			to make your objects and function capable of use in 'with' 
			statements by using the 'contextlib' built-in module.
		This module contains the 'contextmanger' decorator, which lets a simple 
			function be used in 'with' statements.  Ths is much easier than 
			defining a new class with the special methods 
			(__enter__, __init__, __exit__), the standard way.
		The default log level for my program is WARNING, so only the error 
			message will print. (This  wasn't the case for me. I got wierd 
			results, need to investigate. So, I just copied directly from 
			book.) ***I think i know why I got weird results...the 'yield' 
			statement!!! Now that I know what 'yeild' does.  I still need 
			to revist this, though. To make sure.
				def my_function():
					logging.debug('Some debug data')
					logging.error('Error log here')
					logging.debug('More debug data')

				>>> my_function()
				Error log here

		The code below elevates the log level temporarily by defining a context 
			manager.  The yield expression is the point at which the with 
			block's contents will eecute.
				@contextmanager
				def debug_loggging(level):
				    logger = logging.getLogger()
				    old_level = logger.getEffectiveLevel()
				    print(old_level)
				    logger.setLevel(level=level)
				    try:
				        yield
				    finally:
				        logger.setLevel(old_level)
		Now we can call the logging function again, but in the debug_logging 
			context.  All of the debugging messages will print during the 
			'with' block, but the same function running outside the 'with' 
			block won't print debug messages.
				with debug_logging(logging.DEBUG):
					print('Inside')
					my_function()
				print('After')
				my_function
				>>>
				Inside:
				Some debug data
				Error log here
				More debug data
				After:
				Error log here

		Using 'with' Targets
			The 'context_manager', passed to a 'with' statement, may also 
				return an object. This gives the code running in the 
				'with' block the ability to directly intereact with its 
				context. 
				[ with open('my_output.txt') as hanlde: handle.write() ]
				handle is the target. This allows the __exit__ function, 
				which always executes to handle cleanup.

		<Item 40: Consider Coroutines to Run Many Functions Concurrently>
		This can also be done by "yielding" a value from your context manager.  
			In that case you can use the finally statement 
				(not the __exit__ magic method).
					@contextmanager
					def debug_loggging(level):
					    logger = logging.getLogger()
					    old_level = logger.getEffectiveLevel()
					    print(old_level)
					    logger.setLevel(level=level)
					    try:
						yield
					    finally:
						logger.setLevel(old_level)
		Calling logging methods like debug on the 'as' target will produce 
			output because the severity level is set low enough in the 
			'with' block.  Bus using the 'logging' module directly won't 
			print anyting; it's default is WARNING.
				with log_level(logging.DEBUG, 'my-log') as logger:
					logger.debug('This is my message')
					logging.debug('This will not print')
				>>>
				This is my message
		Calling debug logging methods on the 'Logger' named 'my-log' will not print anyting 
			because the default logging severity has be restored. Error log messages will 
			always print.
				logger = logging.getLogger('my-log')
				logger.debug('Debug will not print')
				logger.error('Error will print')
				>>>
				Error will print
		The key here is the 'with' statement allows you to reuse logic from 'try/finally' 
			blocks and reduce visual noise.  Also, the 'contextlib' module provides a 
			'contextmanager' decorator that makes it easy to use your won functions in 
			'with' statements.
		Finally, the value yielded by context managers is supplied to the 'as' part of the 
			'with' statement.  It's useful for letting your code directly access the cause 
			of the special context.

Item 20: Use 'None' and Docstrings to specify Dynamic Default Arguments (Must do a check for 'None')

			In[*]: from datetime import datetime
			In[*]: from time import sleep
			In[*]: def log(message, when=datetime.now()):
			           print('%s: %s' % (when, message))
			    
			In[*]: log('Hi there')
			2017-10-02 17:26:28.871033: Hi there
			In[*]: sleep(.1)
			In[*]: log('Hello there')
			2017-10-02 17:26:28.871033: Hello there	
	In the below code, when executed twice (as shown above), the timestamps would be the same 
		because 'datetime.now' is only executed once, when the functionis defined.  Default 
		argumet values are evaluated only once per module load, which usually happens when the 
		program starts up.  After the module containing this code is loaded, the 'datetime.now' 
		default argument will never be evaluated again.
	By default the keyword, when set to None, you preserve the keyword nature and allow the user 
		to pass in a value or not.
			def log(message, when=None): 
				when = datetime.now() if when is None else when
				print('%s: %s' % (when, message))
	This is especially important when using mutable data (lists, dictionaries, sets). Remember in 
		Python immutable data are pass by reference.  Immputable data (strings, tuples, 
		integers) are pass by value.  So in the code below:
			import json
			def decoe(data, defuat={}):
			    try:
			        return json.loads(data)
			    except ValueError:
			        return default
			    
			def decoe(data, default={}):
			    try:
			        return json.loads(data)
			    except ValueError:
			        return default
			    
			In[*]: foo = decoe('bad data')
			In[*]: print(foo)
			{}
			In[*]: foo['stuff'] = 5
			In[*]: print (foo)
			{'stuff': 5}
			In[*]: bar = decoe('also bad')
			In[*]: print(foo)
			{'stuff': 5}
			In[*]: print(bar)
			{'stuff': 5}
			In[*]: bar['meep'] = 1
			In[*]: print(bar)
			{'stuff': 5, 'meep': 1}
			In[*]: jarr = decoe('really bad')
			In[*]: print(jarr)
			{'stuff': 5, 'meep': 1}
	Because both foo and bar are initially assigned to default, they hold the same reference.  
		Modifying foo modifies anyone enters a bad json object, because doing so returns a 
		refernce to default. Keep in mind, default only gets assigned once!!! So, assigning it 
		to 'None' first, documenting the operations in the docstring, then performing a check 
		on default, all fix the issue.
			def decode(data, default=None):
				"""Demonstrates that 1) keyword args only get set once, when
				   the function is pulled into memory.  Once set to something

				Args:
				data:       JSON data to decode
				default:    Value to return if decoding fails.  Defaults
				            to an empty dictionary.  However, because
				            Keywords only get loaded once, modifing the
				            dictionary after being called, permenently
				            modifies the refernce.
				"""
				default = {} if default is None else default

				try:
					return json.loads(data)
				except ValueError:
					return default

Item 22: Prefer Helper Classes Over Bookkeeping with Dictionaries and Tuples
	Python's classes and inheritance make it easy to express our program's intended 
		behaviors with objects. They provide flexibility in an environment of
		changinge requirements. Knowing how to use them well enables ou to write
		maintainable code.
	
	Python's built-in dictionary type is wondrful for maintaining dynamic cinternal state over the lifetime of an object. Dynamic means situations in which you need to do bookkeeping for an unexpected set of identifiers.
	
	For example, you can defin a class to sotre the names in a dictionary instead of using a predefined attribute.
			class SimpleGradebook(object):
			    def __init__(self):
				self._grades = {}

			    def add_student(self, name) -> None:
				self._grades[name] = []

			    def report_grade(self, name, score) -> None:
				self._grades[name].append(score)

			    def average_grade(self, name) -> int:
				grades = self._grades[name]
				return sum(grades) / len(grades)
	
	Using the class is simple
			book = SimpleGradebook()
			book.add_student('Isaac Newton')
			book.report_grade('Isaac Newton', 90)
			print(book.average_grade('Isaac Newton'))
			>>>
			90.0
	
	Dictionaries are so easy to use that there's a danger of overextending them to write brittle code.
	
	

*
*
*
*
This information was gathered from reading Head First Python. 
*
*
*
*
****    Chapter 10 - Function Decorators: Your Web Server Runs Your Code    ****
When Flask runs your webapp on your computer, it keeps your code in memory all of the time.  When Flask 
	runs on your computer, your webapp code runs directly, resulting in 'app.run' 
	(i.e. 'if __name__ == '__main__': app.run(debug=True) ') line executing.
However, when a web server is configure to execute your code your webapp's code is imported, and the 
	app.run line does not run.
The web server runs your code as it sees fit.  The web server may load/unload parts of your code as 
	needed.  That can lead to problems with storing your webapp state in variables.  Any values 
	associated with global variables are likely lost, and are going to be reset to their starting 
	value when your code is next imported. Storing your webapp's state in a global variable is a bad idea.
We need two things: 1) a way to store variables withou using globals and 2) a way to keep one webapp 
	user's data from interfering with another.  By providing state, the 'session' dictionary takes 
	care of both of these tasks.
By importing 'session' [from flask import session] you give you webapp the ability to remmeber state. 
	Additionally, any data stored in 'session' is keyed by a unique browser cookie, which ensures 
	your session data is kept away from that of every other user of your webapp. 
To enable this, you need to seed Flask's cookie generation technology with a "secret key" 
	[app.secret_key = "<gnerated value>"] which is used by Flask to encrypt your cookie.
The session dictionary maintains a browser-identifiable value by storing a cookie within each browser.  
	From each browser's perspective, it's as if there is only ever one value of data -- the one 
	associated with their cookie.
Remember when using a dictionary it's better to check in and use pop, than check value, if possible 
	prefer: [if 'logged_in' in session: print('Found it')] over 
	[if session['logged_in']: print('Found it')]. When clearing use: [ session.pop('logged_in') ]
Decorators are Python syntax for allowing one function to modify another function at 
	runtime.  
To use a decorator you need to know four things: 1) How to create a function. 2) How to pass a 
	function as an argument to a function. 3) How to return a function from a function. And, 
	4) how to process any number and type of function arguments.

How to pass a function as a function:
	Remember everything in Python is an object.  Functions are actually function objects, equipped 
		with an object ID. (You can see this id with the 'id' BIF.)  

	When a function object is passed to another function, the receiving function can invoke the 
		passed-in function object: 
		[ def apply(func: object, value: object) -> 'object': return func(object) ] 

How to return a function from a function.
	Python allows nested (inner) functions, function that are created from within the suite of an 
		existing function. This technique is helpful for a complex function with many lines of 
		code.  
	When you use a function object as an argument to a function, you can have the receiving 
		function invoke the passed-in function object by appending parenthses.
	A more common usage is for the enclosing function to return the nested function as its value.  
		This is what allows you to create a decorator. The example below illustrates:
			def outer():
				def inner():
					print('This is inner')

				print('Outer is now returning inner (not calling, returning)')
				return inner

			In[*]: i = outer()
			This is outer calling inner (not returning, calling)

			In[*]: type(i)
			function

			In[*]: i()
			This is inner

How to process any number and type of function arguments
	The star args parameter can be processed as a list of arguments (even though it's a tuple).  
		Using this technique you can pass a list or you can instruct the interpreter to expand 
		the list so that it processes the elements of the list and individual arguments. To do 
		the latter, pass the variable proceeding after the * operator.
	Keyword args are defined by the ** operator and represent keyword value pairs.
			def myfuct2(**kwargs):
				for v, v, in kwargs.items():
					print(k, v, sep='|', end=' ')
				if kwargs:
					print()
	When passing in the ** operater it tells the interpreter to treat the interpreter as a 
		collection of keys and their associated value.

To create a decorator you nned to understand that: 1) a decorator is a function, 2) a decorator takes the decorated function as an argument 3) a decorator returns a new function 4) a decorator maintains the decorated functions signature

When a decorator is applied to an xisting function any calls to the existing function are replaces by calls to the function the decorator returns.  In the example below this is the wrapper() function.
		def check_status(func: 'function'):
	    def wrapper():
	        if 'logged_in' in session:
	            return func
	        return "Sorry your're not logged in"
	    return wrapper
    However, the *calling characteristics* need to be maintained too.  Using star-args and **kwargs does the trick.  It genericizes any function signature. 

Using decorators can cause strange behavior in tools that do introspection, such as debuggers, help(), print(), id(), repr(), etc.

Always decorate all decorators with the functools.wraps function. This decorator wil copy all of the important metadata about the inner function to the outer function.
		def trace(func):
			@wraps(func)
			def wrapper(*args, **kwargs)
				result = function(*args, **kwargs)
			return wrapper

		@trace
		def check_status

As with class decorators in Java, Python's function decorators allows you to augment an existing function with extra code, by changing the behavior of the existing function without changing its code.

Decoraters are concerned with augmenting existing functions with additional functionality. Decorator code is under no obligation to do anything after it invokes the decorated function.  The decorator behavior is very different from teh protocol that context managers are epexted to adhere to. Context managers are more interested in ensuring your code executes wthin a specific context, arranging for code to run before a with statemetn as well as enursing that code *always* executes fter a with statement.
*
*
*
*
****    Chapter 11 - Exception Handling: What to Do When Things Go Wrong    ****
Context managers have three menthods to their protocol: __enter__, __init__, and __exit__. If an exception occurs during __enter__, the 'with' statement terminates and any call to __exit__ is cancelled. If __enter__ runs into trouble, __exit__ can no longer assume the context is initialized and configured correctly, so it's prudent not to run the __exit__ code.

Creating a new exception is as simple as extending the 'Exception' class. [ class CustomError(Exception): pass ]

When an exception is raised within 'with''s suite and *not* caught, the 'with' statement arranges to pass details of teh uncaught eception into your context manager's __exit__ method, where you have the option of doing something about it. It's best to put the error checking after any clean up code, guatanteeing the code will run.
*
*
*
*
****    Chapter 11.75 - A Little Bit of Threading: Dealing with Waiting    ****
The decorator, 'copy_current_request_context', ensures that the HTTP request that is active when a functon is called *remains* active even when the function is subsequently executed in a thread.  There is a caveat, the function being decorated haas to be defined ****within*** the function that calls it!! THE DECORATED FUNCTION MUST BE NESTED INSIDE ITS CALLER (as an inner function).
*
*
*
*
*  		This section includes both Head First Python and Effective Python.  The Effective Python sections span the following items.  Each Effective Python bullet point is designated by page number. If no page number exists, then the bullet point is from Head Frist Python.
*
* Item 7: Use List Comprehension Instead of 'map' and 'filter'
* Item 9: Consider Generator Expressions for Large comprehensions
****    Chapter 12 - Advanced Iteration: Looping Like Crazy    ****
Comprehensions are a compact syntax providing way to derive one one list from another. [15]

he function read() prints the whole file: [ with open('file.txt') as raw_data: raw_data.read() ]. Python provides a csv reader: [ import csv; with open('file.csv') as data: for line in csv.reader(data): print(line)]. Line is a list of string elements: ['colum1', 'column2']

'csv' also provides a DictReader function.  It returns the header into the keys for each dictionary line.
				In[*]: filename = '/Users/syeedode/generic_projects/python_code/head_first_python_source/ch12/buzzers.csv'
				In[*]: import csv
				In[*]: with open(filename) as data: 
							for line in csv.DictReader(data):
								print(line)
				In[*]: 
				OrderedDict([('TIME', '09:35'), ('DESTINATION', 'FREEPORT')])
				OrderedDict([('TIME', '17:00'), ('DESTINATION', 'FREEPORT')])
				OrderedDict([('TIME', '09:55'), ('DESTINATION', 'WEST END')])
				OrderedDict([('TIME', '19:00'), ('DESTINATION', 'WEST END')])
				OrderedDict([('TIME', '10:45'), ('DESTINATION', 'TREASURE CAY')])
				OrderedDict([('TIME', '12:00'), ('DESTINATION', 'TREASURE CAY')])
				OrderedDict([('TIME', '11:45'), ('DESTINATION', 'ROCK SOUND')])
				OrderedDict([('TIME', '17:55'), ('DESTINATION', 'ROCK SOUND')])

A comprehension is more of a design pattern than an operation.
				[<append this <iterated element> to the new list [operations on this field are optional]> for <iterated element>  in <iterable list>]
	List allow you to easily skip items in a data structure using if. [16 For example say you want to find the squares of each number in a list. [15]
				In[*]: a = [1, 2, 3, 4, 5, 6, 7, 8]
				In[*]: squares = [x**2 for x in a]
				In[*]:
	Unlike 'map' list comprehensions let you easily filter items from the input list, removing corresponding outputs from the result. [15]
				In[*]: even_squares = [x**2 for x in a if x % 2 == 0]
	The 'filter' BIF can be used along with 'map' to acheive the same thing. However, it is much more visually noisier and harder to read. [16]
				In[*]: alt = map(lamda x: x**, filter(lamda x: x % 2 == 0, a))

Comprehensions provide two benefits.  First, Python is optimized to run comprehensions as quickly as possible.  Second, the comprehensions are performed in place, which has added benefits.

Dictionaires and sets have thier own comprehensions as well.  They make it easier to create deriviative data structures.  Note that the dictionary comprehension ends in braces '{}'  not in brakcets '[]'
				{ <append this <<key>:<value>> to the end of the dictionry>  for <key>,<value> in <iterable key, value entry set> }
Using the above
				from datetime import datetime
				def convert2ampm(time24: str) -> 'str':
					return datetime.strptime(time24, '%H:%M').strftime('%I:%M%p')

				flights = [data for data in open(filename) ]
				flights
				Out[86]:
				['TIME,DESTINATION\n',
				 '09:35,FREEPORT\n',
				 '17:00,FREEPORT\n',
				 '09:55,WEST END\n',
				 '19:00,WEST END\n',
				 '10:45,TREASURE CAY\n',
				 '12:00,TREASURE CAY\n',
				 '11:45,ROCK SOUND\n',
				 '17:55,ROCK SOUND\n']

				with open(filename) as data:
				    data.readline()
				    print(data)
				    flights = {}
				    for line in data:
				        print(line)
				        k,v = line.strip().split(',')
				        flights[k] = v
				    print(flights)

				flights
				Out[88]:
				{'09:35': 'FREEPORT',
				 '09:55': 'WEST END',
				 '10:45': 'TREASURE CAY',
				 '11:45': 'ROCK SOUND',
				 '12:00': 'TREASURE CAY',
				 '17:00': 'FREEPORT',
				 '17:55': 'ROCK SOUND',
				 '19:00': 'WEST END'}

				flights2 = {convert2ampm(k):v.title() for k,v in flights.items() }
				flights2
				Out[92]:
				{'05:00PM': 'Freeport',
				 '05:55PM': 'Rock Sound',
				 '07:00PM': 'West End',
				 '09:35AM': 'Freeport',
				 '09:55AM': 'West End',
				 '10:45AM': 'Treasure Cay',
				 '11:45AM': 'Rock Sound',
				 '12:00PM': 'Treasure Cay'}

Dictcomps can be filtered as well [ freeports_flights = {convert2ampm(k):v.title() for k,v in flights.items() if v == 'FREEPORT'} ]
				freeports_flights
				Out[94]: {'05:00PM': 'Freeport', '09:35AM': 'Freeport'}

				west_end_flights = [time for time,dest in flights2.items() if dest == 'West End']
				west_end_flights
					Out[109]: ['09:55AM', '07:00PM']
				for dest in set(flights2.values()):
					print(dest, '->', [time for time,location in flights2.items() if location == dest])
				Treasure Cay -> ['10:45AM', '12:00PM']
				Freeport -> ['09:35AM', '05:00PM']
				West End -> ['09:55AM', '07:00PM']
				Rock Sound -> ['11:45AM', '05:55PM']

				for dest in set(flights2.values()):
				    when[dest] = [time for time,location in flights2.items() if location == dest]
				when
				Out[117]:
				{'Freeport': ['09:35AM', '05:00PM'],
				 'Rock Sound': ['11:45AM', '05:55PM'],
				 'Treasure Cay': ['10:45AM', '12:00PM'],
				 'West End': ['09:55AM', '07:00PM']}

				flight_times_by_group = { dest:[time for time,location in flights2.items() if location == dest] for dest in set(flights2.values()) }
				flight_times_by_group
				Out[122]:
				{'Freeport': ['09:35AM', '05:00PM'],
				 'Rock Sound': ['11:45AM', '05:55PM'],
				 'Treasure Cay': ['10:45AM', '12:00PM'],
				 'West End': ['09:55AM', '07:00PM']}

When you come across something that looks like a listcomp but is surrounded by parenthesis, your are looking at a generator. The generator and the listcomp produce the same data. However they do not execute the same way.

When a listcomp executes, it produces *all* of the data before doing any other processing.  This means that if a listcomp is processing a lot of data, delays any other processing from unit, it the data is produced.

A generator releases the data a soon as the data is produced by the generator's code.  Any data items produced by the generator executes immediately.  There is no waiting.
				for resp in [requests.get(url) for url in urls ]:
					print(len(resp.content), '->', resp.status_code, '->', resp.url)
				31590 -> 200 -> http://www.headfirstlabs.com/
				37419 -> 200 -> https://www.oreilly.com/
				326180 -> 200 -> https://twitter.com/
				for resp in (requests.get(url) for url in urls ):
					print(len(resp.content), '->', resp.status_code, '->', resp.url)
				31590 -> 200 -> http://www.headfirstlabs.com/
				37419 -> 200 -> https://www.oreilly.com/
				325078 -> 200 -> https://twitter.com/
There was a noticiable delay in the listcomp code.  The generator code, however, returned one at a time. There was a noticible difference.  Putting that code in a function which returns a tuple(<con>, <staus>, <url>) would be problematic with a gnerator.

When a function executes a return statment, the function terminates.  When returning the results of the for loop the uses a generator, use 'yield' instead.  The 'yield' keyword was added to support the creation of *generator functions*. 

You can use yield anywhere a return is used. When you do, you function morphs into a generator function that can be called from any iterator.

When used as an interater, the generator function's 'yield' communicates directly witht the calling for loop as soon as the data is available.  The generator function then blocks, until the calling for loop completes with the data. 




































